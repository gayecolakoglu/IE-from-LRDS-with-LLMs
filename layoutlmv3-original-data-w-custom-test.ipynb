{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b414ba70-ee4b-4922-83c8-cbeead6ef604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from modules.data_processing import *\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a1f4a6-8390-4764-b61d-6a9c6c1f1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_splits(dataset_key: str, split_file_name: str) -> dict[list]:\n",
    "    path_split_file: Path = Path(f'vrdu/{dataset_key}/few_shot-splits/{split_file_name}')\n",
    "    \n",
    "    with open(path_split_file, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_labels_and_splits(dataset_key: str, split_file_name: str) -> tuple[list, dict, dict, dict]:\n",
    "    data_splits: dict = load_data_splits(dataset_key, split_file_name)\n",
    "\n",
    "    dataset_splits: dict = {\n",
    "        \"train_split\": data_splits['train'],\n",
    "        \"valid_split\": data_splits['valid'],\n",
    "        \"test_split\": data_splits['test']\n",
    "    }\n",
    "\n",
    "    label_list = ['O']\n",
    "    labels: list = list(data_splits['train_entity_number_dict'].keys())\n",
    "    for label in labels:\n",
    "        label_list.append(f'B-{label.upper()}')\n",
    "        label_list.append(f'I-{label.upper()}')\n",
    "    id2label: dict = {k: v for k, v in enumerate(label_list)}\n",
    "    label2id: dict = {v: k for k, v in enumerate(label_list)}\n",
    "\n",
    "    return label_list, id2label, label2id, dataset_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b05e65-0c4d-4250-b5a6-d905da63593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = 'vrdu/'\n",
    "split_file_name = 'FARA-lv3-unk_Short-Form-train_10-test_300-valid_100-SD_0.json'  # Update the path to where your split files are located\n",
    "dataset_key= 'registration-form'\n",
    "path_extraction_folder = 'layoutlmv3_outputs/FARA-lv3-unk_Short-Form-train_10-test_300-valid_100-SD_0'\n",
    "path_extraction_folder_test = 'layoutlmv3_outputs/deneme-2/FARA-lv3-Short-Form-combined'\n",
    "label_list, id2label, label2id, dataset_splits = get_labels_and_splits(dataset_key, split_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b09887-f660-44fd-bfb3-b09b79c6347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-FILE_DATE',\n",
       " 'I-FILE_DATE',\n",
       " 'B-FOREIGN_PRINCIPLE_NAME',\n",
       " 'I-FOREIGN_PRINCIPLE_NAME',\n",
       " 'B-REGISTRANT_NAME',\n",
       " 'I-REGISTRANT_NAME',\n",
       " 'B-REGISTRATION_NUM',\n",
       " 'I-REGISTRATION_NUM',\n",
       " 'B-SIGNER_NAME',\n",
       " 'I-SIGNER_NAME',\n",
       " 'B-SIGNER_TITLE',\n",
       " 'I-SIGNER_TITLE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997c2eb9-39a3-488b-9e92-73dfd865a234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-FILE_DATE',\n",
       " 2: 'I-FILE_DATE',\n",
       " 3: 'B-FOREIGN_PRINCIPLE_NAME',\n",
       " 4: 'I-FOREIGN_PRINCIPLE_NAME',\n",
       " 5: 'B-REGISTRANT_NAME',\n",
       " 6: 'I-REGISTRANT_NAME',\n",
       " 7: 'B-REGISTRATION_NUM',\n",
       " 8: 'I-REGISTRATION_NUM',\n",
       " 9: 'B-SIGNER_NAME',\n",
       " 10: 'I-SIGNER_NAME',\n",
       " 11: 'B-SIGNER_TITLE',\n",
       " 12: 'I-SIGNER_TITLE'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a596b771-f4c2-4b9e-abbd-feeb7310eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import pymupdf\n",
    "from PIL import Image  # Import the Image class from the PIL library\n",
    "import io \n",
    "import subprocess\n",
    "\n",
    "def load_dataset_item(dataset_key: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Loads dataset items from a single compressed .jsonl.gz file.\n",
    "    \n",
    "    Args:\n",
    "        dataset_key (str): The key used to locate the specific dataset folder.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each representing an individual dataset item with \n",
    "                    fields like 'filename', 'ocr', and 'annotations'.\n",
    "    \"\"\"\n",
    "    dataset_items = []\n",
    "    path_to_file = Path(f\"{PROJECT_ROOT}/{dataset_key}/main/dataset.jsonl.gz\")\n",
    "\n",
    "    # Open and read the compressed .jsonl.gz file line-by-line\n",
    "    with gzip.open(path_to_file, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            item_data = json.loads(line)  # Each line is a JSON object\n",
    "            dataset_items.append(item_data)\n",
    "\n",
    "    return dataset_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89469f0-7836-4212-bb6a-70a6b83513df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_key: str, path_extraction_folder: Path, data_splits: dict, label2id: dict[str: int],\n",
    "                    id2label: dict[int: str]) -> tuple[Dataset, Dataset, Dataset]:\n",
    "    processed_files = set()\n",
    "    \n",
    "    def _unnormalize_bbox_for_layoutlmv3(bbox: list[int, float], factor: int = 1000) -> list[float]:\n",
    "        x_min: float = bbox[1]\n",
    "        y_min: float = bbox[2]\n",
    "        x_max: float = bbox[3]\n",
    "        y_max: float = bbox[4]\n",
    "\n",
    "        return [\n",
    "            x_min * factor,\n",
    "            y_min * factor,\n",
    "            x_max * factor,\n",
    "            y_max * factor\n",
    "        ]\n",
    "\n",
    "    def _convert_pdf_image_to_pillow_objects(dataset_key: str, file_name: str) -> list:\n",
    "        pillow_images: list = []\n",
    "        processed_paths = set()\n",
    "        path_image_file: Path = Path(fr\"{PROJECT_ROOT}/{dataset_key}/main/pdfs/{file_name}\")\n",
    "        print(\"FILENAME: \", file_name)\n",
    "        pdf_file = pymupdf.open(path_image_file)\n",
    "        print(\"TOTAL PAGENUM: \", len(pdf_file))\n",
    "        \n",
    "        for page_number in range(len(pdf_file)):\n",
    "            print(\"PROCESSING page_number: \", page_number)\n",
    "            page = pdf_file[page_number]\n",
    "            for image_index, img in enumerate(page.get_images(), start=1):\n",
    "                xref = img[0]\n",
    "                # extract image bytes\n",
    "                base_image = pdf_file.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                # get image extension\n",
    "                image_ext = base_image[\"ext\"]\n",
    "\n",
    "                if image_ext == 'jb2':\n",
    "                    print(\"-----IMAGE is: \", image_ext)\n",
    "                    \n",
    "                    # Create output directory for converted images\n",
    "                    output_dir = Path(fr\"{PROJECT_ROOT}/{dataset_key}/main/jb2_images/{file_name.split('.pdf')[0]}\")\n",
    "                    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                    # Check if the PNG images already exist for the current page\n",
    "                    img_files = list(output_dir.glob(f\"img-{page_number + 1}*.png\"))  # For jb2, naming pattern is \"img-<page_number>.png\"\n",
    "                    if not img_files:  # If no images exist for the current page\n",
    "                        try:\n",
    "                            # Use pdftocairo to convert the PDF page to PNG\n",
    "                            command = (\n",
    "                                f\"pdftocairo -png -f {page_number + 1} -l {page_number + 1} \"\n",
    "                                f'\"{str(path_image_file)}\" \"{str(output_dir / \"img\")}\"'\n",
    "                            )\n",
    "                            subprocess.run(command, shell=True, check=True)\n",
    "                        except subprocess.CalledProcessError as e:\n",
    "                            print(f\"Error converting {file_name} to PNG: {e}\")\n",
    "                \n",
    "                    # Append PNG images to pillow_images\n",
    "                    for img_file in output_dir.glob(f\"img-{page_number + 1}*.png\"):\n",
    "                        if str(img_file) not in processed_paths:  # Avoid duplicates\n",
    "                            processed_paths.add(str(img_file))\n",
    "                            pil_image = Image.open(img_file).convert('RGB')\n",
    "                            pillow_images.append((pil_image, str(img_file)))\n",
    "                else:\n",
    "                    # Create output directory for other formats\n",
    "                    output_dir = Path(fr\"{PROJECT_ROOT}/{dataset_key}/main/pngs/{file_name.split('.pdf')[0]}\")\n",
    "                    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                    # Define the output path for non-jb2 images\n",
    "                    output_path = output_dir / f\"page_{page_number + 1}.png\"\n",
    "                    \n",
    "                    if str(output_path) not in processed_paths:\n",
    "                        processed_paths.add(str(output_path))\n",
    "                    \n",
    "                        # Save non-jb2 image directly\n",
    "                        pil_image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "                        pil_image.save(output_path)\n",
    "                        pillow_images.append((pil_image, str(output_path)))\n",
    "\n",
    "        return pillow_images\n",
    "\n",
    "    my_hf_train_ds: list = []\n",
    "    my_hf_valid_ds: list = []\n",
    "    \n",
    "    for dict_item in load_dataset_item(dataset_key):\n",
    "        file_name: str = dict_item[\"filename\"]\n",
    "        if file_name in data_splits['train_split'] or file_name in data_splits['valid_split']:\n",
    "            \n",
    "            if file_name not in processed_files:\n",
    "                # Call the conversion function and add to processed_files\n",
    "                images_and_paths = _convert_pdf_image_to_pillow_objects(dataset_key, file_name)\n",
    "                processed_files.add(file_name)\n",
    "            else:\n",
    "                print(f\"Skipping conversion for {file_name}, already processed.\")\n",
    "        \n",
    "            annotation_counter: int = 0\n",
    "            if len(images_and_paths) != len(dict_item['ocr']['pages']):\n",
    "                print(images_and_paths)\n",
    "                raise ValueError(f\"Mismatch between number of images and OCR pages for {file_name}. Len in folder: {len(images_and_paths)} and len in dict: {len(dict_item['ocr']['pages'])}\")\n",
    "\n",
    "            for page_number, (page, (pil_image, image_path)) in enumerate(zip(dict_item['ocr']['pages'], images_and_paths)):\n",
    "                tokens: list = []\n",
    "                bboxes: list = []\n",
    "                ner_tags: list = []\n",
    "                page_id = page.get(\"page_id\", page_number)\n",
    "                dimension = page.get(\"dimension\", {})\n",
    "                width, height = dimension.get(\"width\"), dimension.get(\"height\")\n",
    "              \n",
    "                for token in page['tokens']:\n",
    "                    tokens.append(token['text'])\n",
    "                    unnormalized_bbox: list[float] = _unnormalize_bbox_for_layoutlmv3(bbox=token['bbox'])\n",
    "                    bboxes.append(unnormalized_bbox)\n",
    "                    \n",
    "                    ner_tag_id: int = label2id['O']\n",
    "                    for segment in token['segments']:\n",
    "                        for annotations in dict_item['annotations']:\n",
    "                            ner_tag: str = annotations[0]\n",
    "                            for annotation in annotations[1]:\n",
    "                                annotation_counter += 1\n",
    "                                annotated_segments: list = annotation[2]\n",
    "                                for annotation_segment in annotated_segments:\n",
    "                                    if annotation_segment[0] <= segment[0] <= segment[1] <= annotation_segment[1]:\n",
    "                                        ner_tag_id = ner_tag.upper()\n",
    "\n",
    "                    if ner_tags:\n",
    "                        last_ner_tag = id2label[ner_tags[-1]]\n",
    "                    else:\n",
    "                        last_ner_tag = id2label[0]\n",
    "\n",
    "                    if ner_tag_id == label2id['O']:\n",
    "                        ner_tags.append(ner_tag_id)\n",
    "                    else:\n",
    "                        if last_ner_tag.split('-')[0] in ['B', 'I']:\n",
    "                            if last_ner_tag.split('-')[1] == ner_tag_id:\n",
    "                                ner_tags.append(label2id[f'I-{ner_tag_id}'])\n",
    "                            else:\n",
    "                                ner_tags.append(label2id[f'B-{ner_tag_id}'])\n",
    "                        else:\n",
    "                            ner_tags.append(label2id[f'B-{ner_tag_id}'])\n",
    "\n",
    "                dataset_dict_item: dict = {\n",
    "                    \"file_identifier\": f'{file_name}__{page_number}',\n",
    "                    \"bboxes\": bboxes,\n",
    "                    \"tokens\": tokens,\n",
    "                    \"ner_tags\": ner_tags,\n",
    "                    \"images\": pil_image,\n",
    "                    \"image_path\": image_path,\n",
    "                    \"image_size\": {'width': width, 'height': height}\n",
    "            }\n",
    "\n",
    "                # Sort dataset item into the different splits, specified in few_shot_split files\n",
    "                if file_name in data_splits['train_split']:\n",
    "                    my_hf_train_ds.append(dataset_dict_item)\n",
    "                if file_name in data_splits['valid_split']:\n",
    "                    my_hf_valid_ds.append(dataset_dict_item)\n",
    "\n",
    "    valid_dataset_unmapped = Dataset.from_list(my_hf_valid_ds)\n",
    "    valid_dataset_unmapped.save_to_disk(fr\"{path_extraction_folder}/unmapped_valid.hf\")\n",
    "\n",
    "    train_dataset_unmapped = Dataset.from_list(my_hf_train_ds)\n",
    "    train_dataset_unmapped.save_to_disk(fr\"{path_extraction_folder}/unmapped_train.hf\")\n",
    "\n",
    "    return valid_dataset_unmapped, train_dataset_unmapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c3825c-d271-4d17-9c21-9be07667e288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILENAME:  19770101_Representative of the Turkish Republic of Northern Cyprus_Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  19901101_Crowell _ Moring International, Ltd._Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  19910701_Representative of the Turkish Republic of Northern Cyprus_Dissemination Report_Dissemination Report.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  19921001_JETRO, New York_Dissemination Report_Dissemination Report.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  19950622_JETRO, Atlanta_Dissemination Report_Dissemination Report.pdf\n",
      "TOTAL PAGENUM:  1\n",
      "PROCESSING page_number:  0\n",
      "FILENAME:  19950710_JETRO, Los Angeles_Dissemination Report_Dissemination Report.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  19990715_Barbados Investment _ Development Corp. Barbados Tourism_Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20080331_JETRO, New York_Yokota, Kunitoshi_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20080530_MSLGROUP Americas, Inc._Pietras, Seth Thomas_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20080725_Hill and Knowlton Strategies, LLC_Kenny, Colleen_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20081223_Hill and Knowlton Strategies, LLC_Stewart, Hanna Ella_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20090420_Podesta Group, Inc._Podesta, Anthony T._Short-Form.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  20090424_BGR Government Affairs, LLC_Cochran, Alexander_Short-Form.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  20090731_Hill and Knowlton Strategies, LLC_Cuneo, Andrew_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20090925_Podesta Group, Inc._Lawrence, Jessica_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20091006_Daniel J. Edelman, Inc._Myers, Richard B._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20091202_MSLGROUP Americas, Inc._Moore, W. John_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100218_Alsalih, Mark K._Alsalih, Mark K._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100514_Hill and Knowlton Strategies, LLC_Kaiser, Christina_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100715_Hill and Knowlton Strategies, LLC_Goldberg, Judy_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100730_CMGRP, Inc._Edmonds, Valerie_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100803_BLJ Worldwide LTD_Karr, Valerie_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20100803_BLJ Worldwide LTD_Sirota, Alexandra_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110204_World Zionist Organization - American Section, Inc._Israeli, Hasia_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110218_Ketchum Inc. NY_Scott, Alexandra_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110311_MSLGROUP Americas, Inc._Lauer, Matthew J._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110311_MSLGROUP Americas, Inc._Silverman, Nicole_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110314_Daniel J. Edelman, Inc._Gibson, Mike_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110314_Daniel J. Edelman, Inc._Hayes, Christopher_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110624_Squire Patton Boggs, LLP_Oresman, Matthew S._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110713_Squire Patton Boggs, LLP_Frideres, Taryn F._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20110823_Akin, Gump, Strauss, Hauer _ Feld, LLP_Gilliland, John R._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120207_Daniel J. Edelman, Inc._Fiedler, Elizabeth_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120221_Akin, Gump, Strauss, Hauer _ Feld, LLP_Parven, Scott_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120327_Caribbean Tourism Organization, USA Inc. _Bramble, Sylma Brown_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120529_KOTRA_Choi, Myunglae_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120608_Ketchum Inc. NY_Knox, Lauren Peterson_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120907_Korea National Tourism Organization, New Jersey_Hong, Junghee_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120920_Commonwealth of Dominica Maritime Registry, Inc._Kapoor, Aditya_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20120920_Commonwealth of Dominica Maritime Registry, Inc._Pama, Yadvinder Singh_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20121128_KOTRA_Jeon, Misung_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130130_JETRO, Atlanta_Kimura, Keiichi_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130307_Podesta Group, Inc._Antelo, Cristina_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130320_Podesta Group, Inc._Chang, Benjamin_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130408_Independent Diplomat, Inc._Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130418_Korea Economic Institute_Hamisevicz, Nicholas_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130513_Commonwealth of Dominica Maritime Registry, Inc._Kaya, Yusuf_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130605_JWI, LLC_Kurz, Jonathan L._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130617_Hill and Knowlton Strategies, LLC_Waltz, Natalie_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20130917_Daniel J. Edelman, Inc._Tyler, Dorothy M_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20131029_Jewish Agency - American Section, Inc._Tal, Ittai_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20131121_Squire Patton Boggs, LLP_Garrett, John C._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20131203_Commonwealth of Dominica Maritime Registry, Inc._Yibo, Zhou_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20140206_Holland _ Knight_Gold, Richard M._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20140207_Commonwealth of Dominica Maritime Registry, Inc._Bagga, Karan_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20140210_Podesta Group, Inc._Kirsch, Steven_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20140303_LB International Solutions, LLC_Borland, Lydia_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "-----IMAGE is:  jb2\n",
      "PROCESSING page_number:  1\n",
      "-----IMAGE is:  jb2\n",
      "FILENAME:  20140306_VisitBritain_Harrison, Kelly_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20140424_Squire Patton Boggs, LLP_Cutts, Matthew D._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20140520_DLA Piper US LLP_Newcomb, Robert Richard_Short-Form.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  20140820_Malaysian Palm Oil Council (f-k-a American Palm Oil Council)_Husin, Norhaznita Binti_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20140922_Ketchum Inc. NY_Adams, Danielle Jenee__Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20141002_Squire Patton Boggs, LLP_Wisner, Frank G_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20141030_Public Strategies Washington, Inc._Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20141110_Adams Jones Law Firm, P.A._Hughes, Patrick B._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20141120_Tourist Office for Flanders, Belgium - New York Office_Vreven, Line_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20150312_Invest Northern Ireland_McClay, Christina_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20150514_Squire Patton Boggs, LLP_Swanson, Stacy A._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20150721_Glover Park Group, LLC_Amendment_Amendment.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20150925_Levick Strategic Communications, LP_Wilson, Justin_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20151130_KOTRA_Kim, Myongsoo_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20160316_Mercury Public Affairs, LLC_Cpin, John_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20160527_KOTRA_Sohn, Soo Deuk_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20160531_Burson-Marsteller, LLC (Washington, DC)_Gaines, Jeremy_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20160622_Husch Blackwell, LLP_McAllister, Singleton_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20160731_Burson-Marsteller, LLC (Washington, DC)_Vega, Mayra_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161031_MSLGROUP Americas, Inc._Bilbray-Axelrod, Shannon_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161031_MSLGROUP Americas, Inc._Holt, Andrew S._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161031_MSLGROUP Americas, Inc._Skiles, M. David_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161031_MSLGROUP Americas, Inc._Young, Paul_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161109_Kuykendall, Gregory J., PC_Kuykendall, Gregory_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20161229_Crowell _ Moring International, Ltd._Bacigalupo, Patricia Wu_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170124_K_L Gates, LLP_Gordon, Barton J._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170206_Japan National Tourism Organization, Los Angeles _Hasegawa, Ryoko_Short-Form.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  20170428_Mer Security and Communication Systems Ltd._Thuemim, Moshe_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170515_Sonoran Policy Group, LLC_Rosenberg, John_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170727_Levick Strategic Communications, LP_Ricci, Andrew Samuel_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170907_McDermott Will _ Emery, LLP_Ryan, Stephen M._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170911_Dowell Pham Harrison, LLP_Vu, Hung Khanh_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170920_DCI Group AZ, LLC_McCabe, Brian_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20170925_White _ Case LLP_Levin, Daniel_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20171010_MSLGROUP Americas, Inc._Harper, Clinton L._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20171121_KOTRA_Kim, Hansoo_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20171129_Muttahida Quami Movement USA_Sattar, Muhammad Farooq_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20171206_Portland PR Inc._Schwark, Sebastian_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20171212_Beckerman_Paul, Jordan_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180130_FTI Consulting (SC), Inc._LaMagna, Matthew_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180202_Quebec Government Office_Dionne, Martin_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180202_Quebec Government Office_Lepage, Annelise Melanie_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180206_Greenberg Traurig, LLP_Forbes, Randy_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180227_Sonoran Policy Group, LLC_Bourge, Christian_Short-Form.pdf\n",
      "TOTAL PAGENUM:  3\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "PROCESSING page_number:  2\n",
      "FILENAME:  20180323_MSLGROUP Americas, Inc._Shapiro, Jared_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180418_BGR Government Affairs, LLC_Rubino, Mike_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180420_MSLGROUP Americas, Inc._Dykes Jr., Anthony Carl_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180430_Development Counsellors International_Meliti, Amalia_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180508_Southern Transitional Council (US), Ltd._Mused, Abdulsalam K._Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180608_Polish Chamber of Commerce in the US_Olchawa, Maciej_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180615_Alcalde _ Fay_Alcalde, Hector_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180629_MMGY Global, LLC_Hughes, Stephanie_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n",
      "FILENAME:  20180705_Luque PLLC_Luque, Anibal_Short-Form.pdf\n",
      "TOTAL PAGENUM:  2\n",
      "PROCESSING page_number:  0\n",
      "PROCESSING page_number:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█| 205/205 [00:00<00:00, 1809.16 examples/\n",
      "Saving the dataset (1/1 shards): 100%|█| 20/20 [00:00<00:00, 1597.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
      "    num_rows: 205\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_splits = dataset_splits\n",
    "valid_dataset_unmapped, train_dataset_unmapped = prepare_dataset(dataset_key, path_extraction_folder, data_splits, label2id, id2label)\n",
    "\n",
    "print(valid_dataset_unmapped)\n",
    "print(train_dataset_unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db947352-c8df-40c4-b99e-1bc3c5754e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images'],\n",
      "    num_rows: 85\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
      "    num_rows: 205\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
      "    num_rows: 20\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "test_dataset_unmapped = load_from_disk(fr\"{path_extraction_folder_test}/unmapped_test.hf\")\n",
    "valid_dataset_unmapped = load_from_disk(fr\"{path_extraction_folder}/unmapped_valid.hf\")\n",
    "train_dataset_unmapped = load_from_disk(fr\"{path_extraction_folder}/unmapped_train.hf\")\n",
    "\n",
    "# Optionally, you can print to verify the datasets are loaded correctly\n",
    "print(test_dataset_unmapped)\n",
    "print(valid_dataset_unmapped)\n",
    "print(train_dataset_unmapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da39aafb-f697-4402-b2e4-e909cd85cf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_unmapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b03700-b625-4a86-91ef-af6c357da2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images', 'image_path', 'image_size'],\n",
       "    num_rows: 205\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset_unmapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6b6f226-a935-45e0-8d39-af0289c2db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1696x2800 at 0x7FC71EA46990>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_unmapped[0]['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9b0aea0-d541-4c67-b2a0-1e91900b70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset_unmapped['images']) == len(train_dataset_unmapped['file_identifier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec3ea66-fa8a-40ec-8823-09a5454c478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset_unmapped['bboxes']) == len(train_dataset_unmapped['tokens']) == len(train_dataset_unmapped['ner_tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493b83b8-2908-4932-9309-6c60f4446930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_identifier': Value(dtype='string', id=None),\n",
       " 'bboxes': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'images': Image(mode=None, decode=True, id=None),\n",
       " 'image_path': Value(dtype='string', id=None),\n",
       " 'image_size': {'height': Value(dtype='int64', id=None),\n",
       "  'width': Value(dtype='int64', id=None)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_unmapped.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9557c990-b4c5-4f81-b544-da679e43a746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_identifier': Value(dtype='string', id=None),\n",
       " 'bboxes': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'images': Image(mode=None, decode=True, id=None),\n",
       " 'image_path': Value(dtype='string', id=None),\n",
       " 'image_size': {'height': Value(dtype='int64', id=None),\n",
       "  'width': Value(dtype='int64', id=None)}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset_unmapped.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dbe06b7-1726-451b-a102-edece336e125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_identifier': '19770101_Representative of the Turkish Republic of Northern Cyprus_Amendment_Amendment.pdf__0',\n",
       " 'bboxes': [[122.75063999999999, 19.462826, 154.24165000000002, 28.026469],\n",
       "  [160.0257, 19.852083, 178.66324, 27.637213],\n",
       "  [178.66324, 20.241339, 182.51929, 28.026469],\n",
       "  [184.4473, 20.241339, 206.29819999999998, 28.415726],\n",
       "  [712.72492, 22.576878, 755.78403, 29.583495000000003],\n",
       "  [759.6401000000001, 22.576878, 798.2004900000001, 29.972753],\n",
       "  [803.3419299999999, 22.966134999999998, 824.55015, 29.972753],\n",
       "  [828.40616, 22.966134999999998, 841.2596599999999, 29.972753],\n",
       "  [842.5449699999999, 22.966134999999998, 845.75838, 29.972753],\n",
       "  [844.4730000000001, 22.966134999999998, 884.3187700000001, 30.362008],\n",
       "  [732.0051199999999, 30.751266, 765.42419, 38.14714],\n",
       "  [770.56557, 31.140521, 813.62468, 38.925651],\n",
       "  [818.1234, 31.140521, 843.83035, 38.536396],\n",
       "  [846.4010400000001, 31.529777000000003, 860.53985, 38.925651],\n",
       "  [861.8251700000001, 31.529777000000003, 865.0385699999999, 38.925651],\n",
       "  [872.10798, 31.529777000000003, 897.81493, 38.925651],\n",
       "  [338.04627999999997, 42.039704, 395.88689999999997, 52.160375],\n",
       "  [404.88431, 42.428959, 465.9383, 52.54963],\n",
       "  [472.36505, 42.818218, 582.2622200000001, 53.328142],\n",
       "  [588.04625, 43.59673, 607.96916, 52.938886],\n",
       "  [616.32389, 43.59673, 682.5192599999999, 53.717400999999995],\n",
       "  [410.02572, 55.274427, 510.28275, 64.616583],\n",
       "  [512.85344, 55.274427, 517.3521599999999, 64.616583],\n",
       "  [525.06429, 55.274427, 559.1259600000001, 64.616583],\n",
       "  [564.26734, 55.274427, 603.47044, 64.616583],\n",
       "  [334.19021999999995, 76.683536, 433.80463000000003, 87.58271500000001],\n",
       "  [440.23135, 77.46204700000001, 457.58355, 87.193459],\n",
       "  [464.65296, 77.46204700000001, 583.54753, 88.361233],\n",
       "  [591.2596599999999, 78.240559, 688.94601, 89.139745],\n",
       "  [599.61438, 89.529, 602.8277899999999, 96.535616],\n",
       "  [392.67352, 99.64966799999999, 460.79692, 112.49513],\n",
       "  [464.65296, 100.03892, 475.5784, 112.10588],\n",
       "  [484.57583999999997, 100.03892, 504.49871999999993, 112.49513],\n",
       "  [510.28275, 100.03892, 566.19537, 112.88439],\n",
       "  [573.90743, 100.42818000000001, 621.46533, 113.27365],\n",
       "  [368.89461, 113.27365, 456.94086, 124.56208000000001],\n",
       "  [464.01027, 113.66291000000001, 488.43187, 124.17283],\n",
       "  [492.2879, 113.66291000000001, 510.92547, 124.17283],\n",
       "  [514.13882, 114.05216, 543.7018300000001, 124.56208000000001],\n",
       "  [547.55783, 114.05216, 552.69921, 124.56208000000001],\n",
       "  [558.4833, 114.05216, 574.55015, 124.56208000000001],\n",
       "  [580.3341899999999, 114.05216, 640.7455199999999, 125.3406],\n",
       "  [641.3881799999999, 114.44142000000001, 646.52956, 124.95133999999999],\n",
       "  [577.7635, 129.62241, 580.3341899999999, 135.07201],\n",
       "  [125.96402, 148.30673, 142.03085, 158.81667],\n",
       "  [149.74293, 148.69599, 190.87404, 159.20591000000002],\n",
       "  [194.73007, 149.08525, 210.79692, 159.59518],\n",
       "  [213.36761, 149.08525, 292.41645, 160.37369],\n",
       "  [523.13626, 151.03152, 539.8457599999999, 161.93071],\n",
       "  [547.55783, 150.25301, 635.6040800000001, 161.93071],\n",
       "  [643.3162100000001, 150.64228, 670.9511299999999, 161.54146],\n",
       "  [145.24421, 169.32659, 205.65553, 179.83651],\n",
       "  [215.9383, 170.49436, 235.86118, 180.22577],\n",
       "  [248.71466, 170.49436, 313.62468, 181.00429000000003],\n",
       "  [147.81491, 182.17205, 218.50900000000001, 192.29272],\n",
       "  [226.22108, 182.95057, 311.69665000000003, 193.46049000000002],\n",
       "  [608.6118200000001, 173.60841, 644.60152, 186.45388],\n",
       "  [127.24936000000001, 206.30595, 143.31619, 219.54067],\n",
       "  [152.95629, 206.69521, 183.80463, 220.3192],\n",
       "  [189.5887, 206.69521, 269.92287999999996, 221.09771],\n",
       "  [273.77891999999997, 207.47373, 286.63239, 220.70844],\n",
       "  [291.77377, 207.47373, 326.47815, 221.48696],\n",
       "  [330.33419000000004, 207.86299, 346.40103999999997, 221.09771],\n",
       "  [352.1851, 207.86299, 431.23393999999996, 221.87622000000002],\n",
       "  [437.66066, 208.6415, 460.15424, 221.87622000000002],\n",
       "  [463.36761, 208.6415, 532.1337000000001, 222.65473],\n",
       "  [535.9897, 209.03074999999998, 604.75576, 223.04399],\n",
       "  [607.96916, 209.80926, 663.23906, 223.82250000000002],\n",
       "  [669.6658100000001, 210.19852, 681.8766, 223.43324],\n",
       "  [686.37532, 210.19852, 750.64266, 224.21175],\n",
       "  [750.64266, 210.97703, 757.0694100000001, 224.21175],\n",
       "  [219.15168, 246.01012, 234.57584, 256.13078],\n",
       "  [242.28791999999999, 246.01012, 292.41645, 256.90931],\n",
       "  [300.77121, 246.78864000000002, 305.26993000000004, 256.90931],\n",
       "  [312.98199, 246.78864000000002, 385.60411, 258.07709],\n",
       "  [393.31621, 247.56715000000003, 405.52700000000004, 257.68781],\n",
       "  [524.42157, 246.39937, 530.2056699999999, 258.07709],\n",
       "  [557.8406500000001, 246.39937, 575.83547, 258.46633],\n",
       "  [582.2622200000001, 246.78864000000002, 609.8972, 258.46633],\n",
       "  [618.89458, 246.78864000000002, 624.67867, 258.46633],\n",
       "  [632.3907399999999, 246.78864000000002, 646.52956, 258.46633],\n",
       "  [647.81493, 247.17788, 653.5989599999999, 258.85558],\n",
       "  [652.3136499999999, 247.17788, 677.37788, 258.85558],\n",
       "  [684.4472900000001, 247.17788, 725.57843, 258.85558],\n",
       "  [732.6478400000001, 247.56715000000003, 746.78665, 259.24483],\n",
       "  [753.8560600000001, 247.56715000000003, 759.6401000000001, 259.24483],\n",
       "  [767.3521599999999, 247.56715000000003, 814.26734, 259.63410999999996],\n",
       "  [821.97946, 247.95640999999998, 832.9048799999999, 259.63410999999996],\n",
       "  [841.2596599999999,\n",
       "   247.95640999999998,\n",
       "   873.3933000000001,\n",
       "   259.63410999999996],\n",
       "  [557.8406500000001, 259.24483, 602.18507, 269.36552],\n",
       "  [608.6118200000001, 259.63410999999996, 625.32133, 269.75476999999995],\n",
       "  [631.10542, 259.24483, 686.37532, 270.14402],\n",
       "  [694.0873899999999, 260.02335999999997, 709.51158, 270.14402],\n",
       "  [717.22364, 260.02335999999997, 767.9948800000001, 270.53328999999997],\n",
       "  [776.99226, 260.02335999999997, 781.4909799999999, 270.14402],\n",
       "  [783.4190100000001, 260.02335999999997, 787.91773, 270.14402],\n",
       "  [788.56039, 260.4126, 793.0591099999999, 270.53328999999997],\n",
       "  [798.8432, 260.4126, 803.3419299999999, 270.53328999999997],\n",
       "  [807.1979299999999, 260.4126, 822.62212, 270.53328999999997],\n",
       "  [826.47812, 260.4126, 847.6863500000001, 270.53328999999997],\n",
       "  [855.39848, 260.4126, 878.53467, 270.53328999999997],\n",
       "  [880.46271, 260.4126, 884.9614300000001, 270.53328999999997],\n",
       "  [253.21338, 270.14402, 298.84317999999996, 279.48618],\n",
       "  [303.3419, 270.53328999999997, 373.39333000000005, 279.87543],\n",
       "  [222.36504000000002, 288.82834, 229.43445, 304.00935],\n",
       "  [254.49872000000002, 288.82834, 352.82776, 304.78783999999996],\n",
       "  [354.75579, 289.21759000000003, 428.02056999999996, 304.39860000000004],\n",
       "  [253.21338, 304.00935, 273.13626, 316.46556],\n",
       "  [282.13367, 304.00935, 329.69153, 316.8548],\n",
       "  [341.25962999999996, 304.39860000000004, 360.53985, 316.8548],\n",
       "  [363.7532, 304.39860000000004, 369.53726, 316.8548],\n",
       "  [380.46274, 304.39860000000004, 417.09512, 316.8548],\n",
       "  [544.34448, 293.88866, 549.48586, 305.17712],\n",
       "  [550.77124, 293.88866, 591.90232, 305.95562],\n",
       "  [595.75838, 293.88866, 649.7429, 305.95562],\n",
       "  [654.88434, 294.27794, 660.0257200000001, 305.56636999999995],\n",
       "  [660.66837, 294.27794, 710.79689, 306.34487],\n",
       "  [715.93833, 294.66718, 721.0797100000001, 305.95562],\n",
       "  [733.29049, 294.66718, 791.7737999999999, 306.73413999999997],\n",
       "  [801.4138899999999, 295.05643, 819.40871, 306.73413999999997],\n",
       "  [829.69153, 295.05643, 897.1722100000001, 307.12339],\n",
       "  [217.22364, 327.75399, 235.86118, 340.21020000000004],\n",
       "  [242.93059, 327.75399, 272.49357000000003, 340.21020000000004],\n",
       "  [276.99228999999997, 328.14324, 324.55012, 340.59945000000005],\n",
       "  [329.69153, 328.14324, 344.47299999999996, 340.59945000000005],\n",
       "  [350.25707, 328.14324, 397.8149, 340.59945000000005],\n",
       "  [405.52700000000004, 328.14324, 417.73778, 340.59945000000005],\n",
       "  [426.09254000000004, 328.53252, 438.30334999999997, 340.98873000000003],\n",
       "  [215.9383, 341.76722, 267.35219, 352.27716],\n",
       "  [271.20823, 341.76722, 345.75835, 352.66641],\n",
       "  [354.11310000000003, 342.15647, 386.88946000000004, 352.66641],\n",
       "  [388.1748, 342.15647, 393.31621, 352.66641],\n",
       "  [124.67866, 377.18958000000003, 141.38818, 388.08876],\n",
       "  [149.10026000000002, 377.18958000000003, 162.5964, 388.08876],\n",
       "  [167.73778000000001, 377.57882, 191.51671000000002, 388.47801],\n",
       "  [199.87147, 377.18958000000003, 276.99228999999997, 388.86726],\n",
       "  [284.70436, 377.57882, 339.97428, 389.25651],\n",
       "  [345.75835, 377.96807, 366.32392000000004, 389.25651],\n",
       "  [372.10798, 378.35735, 411.31106, 389.25651],\n",
       "  [415.16709000000003, 378.35735, 428.02056999999996, 389.25651],\n",
       "  [435.73266, 378.35735, 440.87404000000004, 389.25651],\n",
       "  [446.6581, 378.35735, 515.42419, 390.03503],\n",
       "  [518.63754, 378.7466, 535.34704, 389.64579],\n",
       "  [538.56039, 378.7466, 611.8251700000001, 390.42428],\n",
       "  [615.6812299999999, 379.13585, 620.82261, 390.03503],\n",
       "  [625.9639900000001, 379.13585, 672.2365, 390.42428],\n",
       "  [676.09257, 379.5251, 702.44217, 390.42428],\n",
       "  [121.4653, 390.03503, 127.89202999999999, 403.26977000000005],\n",
       "  [129.82004999999998, 390.03503, 136.24679, 403.26977000000005],\n",
       "  [143.31619, 390.03503, 149.74293, 403.26977000000005],\n",
       "  [160.0257, 390.03503, 226.86375999999998, 403.26977000000005],\n",
       "  [239.07454, 390.03503, 305.91258, 403.26977000000005],\n",
       "  [317.48071, 390.03503, 364.39589, 403.26977000000005],\n",
       "  [373.39333000000005, 390.03503, 415.16709000000003, 403.26977000000005],\n",
       "  [418.38047, 390.03503, 424.80719, 403.26977000000005],\n",
       "  [435.73266, 390.03503, 491.00255999999996, 403.26977000000005],\n",
       "  [496.78662, 390.03503, 503.21335, 403.26977000000005],\n",
       "  [514.13882, 390.03503, 561.05399, 403.26977000000005],\n",
       "  [571.97946, 390.03503, 591.90232, 403.26977000000005],\n",
       "  [593.1876900000001, 390.03503, 599.61438, 403.26977000000005],\n",
       "  [612.46789, 390.03503, 648.45759, 403.26977000000005],\n",
       "  [122.10797, 402.10199, 127.89202999999999, 414.16892],\n",
       "  [132.39075, 402.10199, 138.17479999999998, 414.16892],\n",
       "  [142.03085, 402.10199, 147.81491, 414.16892],\n",
       "  [158.74036, 402.10199, 226.86375999999998, 414.5582],\n",
       "  [238.43187, 402.49123999999995, 286.63239, 414.5582],\n",
       "  [296.27249, 402.49123999999995, 354.11310000000003, 414.5582],\n",
       "  [366.32392000000004, 402.88048999999995, 422.23650000000004, 414.94745],\n",
       "  [433.16194, 402.49123999999995, 529.56301, 415.3367],\n",
       "  [534.70439, 403.26977000000005, 540.48842, 415.3367],\n",
       "  [550.77124, 403.26977000000005, 589.33163, 415.3367],\n",
       "  [610.53985, 402.88048999999995, 656.16965, 414.94745],\n",
       "  [670.30847, 403.26977000000005, 688.94601, 415.3367],\n",
       "  [691.5167, 403.26977000000005, 697.30079, 415.3367],\n",
       "  [710.79689, 403.26977000000005, 748.71463, 415.3367],\n",
       "  [122.10797, 414.16892, 127.89202999999999, 426.23588],\n",
       "  [132.39075, 414.16892, 138.17479999999998, 426.23588],\n",
       "  [142.03085, 414.16892, 147.81491, 426.23588],\n",
       "  [160.66837, 414.16892, 246.78664, 427.01441],\n",
       "  [258.35475, 414.5582, 276.99228999999997, 426.62513],\n",
       "  [288.56041999999997, 414.5582, 327.12081, 426.62513],\n",
       "  [338.04627999999997, 414.5582, 356.68379, 427.01441],\n",
       "  [366.32392000000004, 414.94745, 384.31877, 427.01441],\n",
       "  [395.88689999999997, 414.94745, 461.43958000000003, 427.01441],\n",
       "  [473.65040000000005, 414.94745, 592.5449699999999, 427.79291],\n",
       "  [600.89976, 415.3367, 686.37532, 428.18218],\n",
       "  [698.5861100000001, 415.72598, 726.86374, 427.79291],\n",
       "  [738.43187, 415.72598, 794.34448, 427.79291],\n",
       "  [809.76862, 416.11522, 864.3959199999999, 428.18218],\n",
       "  [158.74036, 426.23588, 209.51156, 439.47062],\n",
       "  [221.07969, 426.23588, 237.14652999999998, 439.47062],\n",
       "  [241.00257, 426.23588, 247.42931000000002, 439.47062],\n",
       "  [259.64009999999996, 426.23588, 296.27249, 439.47062],\n",
       "  [307.19795999999997, 426.23588, 354.75579, 439.47062],\n",
       "  [367.60926, 426.23588, 433.80463000000003, 439.47062],\n",
       "  [446.01542, 426.23588, 452.44217, 439.47062],\n",
       "  [456.94086, 426.23588, 463.36761, 439.47062],\n",
       "  [476.86374, 426.23588, 512.21079, 439.47062],\n",
       "  [122.75063999999999, 437.91360000000003, 131.10539, 455.43012],\n",
       "  [131.74806999999998, 437.91360000000003, 140.10283, 455.43012],\n",
       "  [140.10283, 437.91360000000003, 148.45759, 455.43012],\n",
       "  [160.0257, 437.91360000000003, 286.63239, 455.43012],\n",
       "  [299.48586, 437.91360000000003, 365.03857, 455.43012],\n",
       "  [123.39332, 446.86648, 140.10283, 457.76567],\n",
       "  [149.74293, 446.86648, 181.8766, 458.15492],\n",
       "  [191.51671000000002, 447.25573, 221.72236, 458.15492],\n",
       "  [226.22108, 447.25573, 282.77636, 458.93344],\n",
       "  [291.13111000000004, 447.64501, 332.90488, 458.54419],\n",
       "  [341.25962999999996, 447.64501, 372.75064000000003, 458.93344],\n",
       "  [377.24935999999997, 448.03426, 393.95887, 458.93344],\n",
       "  [401.67096000000004, 448.03426, 466.58099, 459.32268999999997],\n",
       "  [474.29305, 448.4235, 511.56813, 459.32268999999997],\n",
       "  [522.4936, 448.4235, 532.77636, 459.32268999999997],\n",
       "  [539.8457599999999, 448.4235, 568.1234, 459.71193999999997],\n",
       "  [571.3367499999999, 448.81275, 613.7532, 459.71193999999997],\n",
       "  [619.53729, 448.81275, 677.37788, 460.49046999999996],\n",
       "  [682.5192599999999, 449.20203, 712.08227, 460.10121999999996],\n",
       "  [715.29561, 449.20203, 720.43699, 460.10121999999996],\n",
       "  [724.29305, 449.20203, 763.49616, 460.49046999999996],\n",
       "  [771.2082300000001, 449.20203, 849.61438, 460.87971],\n",
       "  [851.54241, 449.98053, 856.6837899999999, 460.87971],\n",
       "  [149.74293, 460.10121999999996, 206.29819999999998, 470.61113],\n",
       "  [214.65296, 460.49046999999996, 281.49100999999996, 471.38965],\n",
       "  [291.77377, 460.49046999999996, 301.41389000000004, 471.0004],\n",
       "  [312.98199, 460.49046999999996, 337.40360000000004, 471.0004],\n",
       "  [345.11569, 460.87971, 396.52956, 471.38965],\n",
       "  [404.88431, 460.87971, 420.95116, 471.38965],\n",
       "  [424.16452999999996, 460.87971, 446.6581, 471.38965],\n",
       "  [453.08483, 460.87971, 482.00515, 471.7789],\n",
       "  [489.07456, 461.26896, 498.71466, 471.7789],\n",
       "  [508.35478, 461.26896, 530.2056699999999, 471.7789],\n",
       "  [535.34704, 461.26896, 615.6812299999999, 472.55743],\n",
       "  [625.9639900000001, 461.65824, 694.7301, 472.55743],\n",
       "  [698.5861100000001, 461.65824, 710.79689, 472.16815],\n",
       "  [717.8662999999999, 462.04749, 758.99744, 472.55743],\n",
       "  [766.70951, 462.04749, 776.3496, 472.55743],\n",
       "  [783.4190100000001, 462.04749, 839.33163, 472.55743],\n",
       "  [841.2596599999999, 462.43674, 846.4010400000001, 472.94667000000004],\n",
       "  [852.18507, 462.43674, 861.8251700000001, 472.94667000000004],\n",
       "  [150.3856, 471.7789, 179.94858, 483.45661],\n",
       "  [187.66066, 471.7789, 230.07712, 483.45661],\n",
       "  [233.93317, 471.7789, 248.07198, 483.45661],\n",
       "  [255.14137999999997, 471.7789, 305.26993000000004, 483.45661],\n",
       "  [305.91258, 471.7789, 311.69665000000003, 483.45661],\n",
       "  [314.91002000000003, 471.7789, 342.54497, 483.45661],\n",
       "  [347.68638000000004, 471.7789, 374.67867, 483.45661],\n",
       "  [383.03342000000004, 471.7789, 424.80719, 483.45661],\n",
       "  [430.59126, 471.7789, 475.5784, 483.45661],\n",
       "  [482.00515, 471.7789, 506.42675, 483.45661],\n",
       "  [510.92547, 471.7789, 528.9202899999999, 483.45661],\n",
       "  [534.06167, 471.7789, 569.40871, 483.45661],\n",
       "  [570.05143, 471.7789, 575.83547, 483.45661],\n",
       "  [124.67866, 501.75166, 163.88174999999998, 514.9864],\n",
       "  [174.16451999999998, 502.14094, 192.80205999999998, 514.59712],\n",
       "  [202.44215, 502.14094, 270.56554, 515.3756099999999],\n",
       "  [280.84832, 502.91944, 299.48586, 515.76489],\n",
       "  [311.69665000000003, 503.30865, 338.04627999999997, 516.15417],\n",
       "  [351.54241, 503.30865, 406.81234, 516.54339],\n",
       "  [418.38047, 504.08721, 458.22623, 516.93267],\n",
       "  [469.15168, 504.47643, 474.93574, 516.93267],\n",
       "  [120.82262, 528.2210699999999, 239.07454, 540.28803],\n",
       "  [251.92803000000004, 528.2210699999999, 320.0514, 540.28803],\n",
       "  [329.69153, 528.2210699999999, 397.8149, 540.28803],\n",
       "  [409.38302999999996, 528.2210699999999, 427.37788, 540.28803],\n",
       "  [430.59126, 528.2210699999999, 436.37532, 540.28803],\n",
       "  [457.58355, 528.2210699999999, 516.70951, 540.6773099999999],\n",
       "  [526.99226, 528.99963, 544.9871400000001, 540.6773099999999],\n",
       "  [557.1979299999999, 528.99963, 622.10798, 541.4558099999999],\n",
       "  [633.03339, 529.38884, 701.1568, 541.8450799999999],\n",
       "  [711.43961, 530.1673999999999, 799.48586, 543.01286],\n",
       "  [456.94086, 540.28803, 487.78920999999997, 552.74427],\n",
       "  [497.42931, 540.28803, 543.0591099999999, 553.13349],\n",
       "  [554.6272399999999, 540.6773099999999, 613.11054, 553.52277],\n",
       "  [617.6092600000001, 541.4558099999999, 623.3933000000001, 553.52277],\n",
       "  [644.60152, 541.4558099999999, 679.94857, 554.3012600000001],\n",
       "  [691.5167, 541.4558099999999, 740.3598999999999, 554.3012600000001],\n",
       "  [456.94086, 553.52277, 485.2185, 565.2004499999999],\n",
       "  [496.78662, 553.91204, 533.4190100000001, 565.58973],\n",
       "  [539.8457599999999, 554.3012600000001, 544.9871400000001, 565.2004499999999],\n",
       "  [555.9126100000001, 554.3012600000001, 580.97684, 565.979],\n",
       "  [596.4010400000001, 554.6905399999999, 633.03339, 566.36822],\n",
       "  [150.3856, 679.6419000000001, 178.02057, 691.3195800000001],\n",
       "  [181.23393, 679.6419000000001, 267.35219, 691.3195800000001],\n",
       "  [273.77891999999997, 679.6419000000001, 317.48071, 691.3195800000001],\n",
       "  [317.48071, 679.6419000000001, 323.26478, 691.3195800000001],\n",
       "  [323.26478, 679.6419000000001, 329.04884, 691.3195800000001],\n",
       "  [330.97686999999996, 679.6419000000001, 336.76094, 691.3195800000001],\n",
       "  [341.90232, 679.6419000000001, 356.04113, 691.3195800000001],\n",
       "  [361.18251000000004, 679.6419000000001, 400.38562, 691.3195800000001],\n",
       "  [402.31361999999996, 679.6419000000001, 408.09768, 691.3195800000001],\n",
       "  [410.02572, 679.6419000000001, 415.80978000000005, 691.3195800000001],\n",
       "  [417.73778, 679.6419000000001, 423.52185, 691.3195800000001],\n",
       "  [426.73522, 679.6419000000001, 456.2982, 691.3195800000001],\n",
       "  [460.79692, 679.6419000000001, 478.79177, 691.3195800000001],\n",
       "  [482.00515, 679.6419000000001, 509.6401, 691.3195800000001],\n",
       "  [519.92285, 679.6419000000001, 548.8432, 691.3195800000001],\n",
       "  [555.2699, 679.6419000000001, 587.4036, 691.3195800000001],\n",
       "  [589.33163, 679.6419000000001, 595.11566, 691.3195800000001],\n",
       "  [600.89976, 679.6419000000001, 629.8200499999999, 691.3195800000001],\n",
       "  [635.6040800000001, 679.6419000000001, 658.09768, 691.3195800000001],\n",
       "  [664.52444, 679.6419000000001, 744.85862, 691.3195800000001],\n",
       "  [750.64266, 679.6419000000001, 772.4936, 691.3195800000001],\n",
       "  [778.27764, 679.6419000000001, 808.4833, 691.3195800000001],\n",
       "  [816.83803, 679.6419000000001, 827.7635, 691.3195800000001],\n",
       "  [836.11828, 679.6419000000001, 863.11054, 691.3195800000001],\n",
       "  [122.10797, 692.48736, 202.44215, 703.77576],\n",
       "  [208.86889, 692.48736, 230.07712, 703.77576],\n",
       "  [238.43187, 692.48736, 265.42416000000003, 703.77576],\n",
       "  [269.92287999999996, 692.48736, 286.63239, 703.77576],\n",
       "  [293.7018, 692.48736, 306.55527, 703.77576],\n",
       "  [314.26734, 692.48736, 319.40874, 703.77576],\n",
       "  [319.40874, 692.48736, 347.68638000000004, 703.77576],\n",
       "  [356.04113, 692.48736, 374.67867, 703.77576],\n",
       "  [379.17739, 692.48736, 384.31877, 703.77576],\n",
       "  [388.1748, 692.48736, 444.73006999999996, 703.77576],\n",
       "  [447.94345000000004, 692.48736, 477.50642999999997, 703.77576],\n",
       "  [484.57583999999997, 692.48736, 505.78403000000003, 703.77576],\n",
       "  [515.42419, 692.48736, 573.26478, 703.77576],\n",
       "  [580.3341899999999, 692.48736, 631.10542, 703.77576],\n",
       "  [634.9614300000001, 692.48736, 658.7403400000001, 703.77576],\n",
       "  [667.0951200000001, 692.48736, 694.0873899999999, 703.77576],\n",
       "  [702.44217, 692.48736, 729.43443, 703.77576],\n",
       "  [737.78921, 692.48736, 798.8432, 703.77576],\n",
       "  [805.2699, 692.48736, 826.47812, 703.77576],\n",
       "  [832.2622200000001, 692.48736, 845.11566, 703.77576],\n",
       "  [850.89976, 692.48736, 885.6040800000001, 703.77576],\n",
       "  [123.39332, 703.77576, 178.02057, 715.8427200000001],\n",
       "  [183.16196000000002, 703.77576, 211.43959, 715.8427200000001],\n",
       "  [219.15168, 703.77576, 241.64525, 715.8427200000001],\n",
       "  [248.71466, 703.77576, 308.48330000000004, 715.8427200000001],\n",
       "  [314.91002000000003, 703.77576, 329.04884, 715.8427200000001],\n",
       "  [334.83290999999997, 703.77576, 357.96916, 715.8427200000001],\n",
       "  [364.39589, 703.77576, 395.24421, 715.8427200000001],\n",
       "  [400.38562, 703.77576, 415.80978000000005, 715.8427200000001],\n",
       "  [420.30847, 703.77576, 440.23135, 715.8427200000001],\n",
       "  [446.6581, 703.77576, 452.44217, 715.8427200000001],\n",
       "  [453.08483, 703.77576, 485.86118, 715.8427200000001],\n",
       "  [486.50387, 703.77576, 492.2879, 715.8427200000001],\n",
       "  [495.50128, 703.77576, 570.05143, 715.8427200000001],\n",
       "  [577.7635, 703.77576, 600.2571, 715.8427200000001],\n",
       "  [607.96916, 703.77576, 649.7429, 715.8427200000001],\n",
       "  [650.38562, 703.77576, 656.16965, 715.8427200000001],\n",
       "  [611.8251700000001, 711.5609000000001, 755.78403, 750.48655],\n",
       "  [581.6195600000001, 758.27169, 622.75064, 769.17088],\n",
       "  [632.3907399999999, 758.27169, 690.8740399999999, 769.56016],\n",
       "  [695.3727600000001, 758.66097, 700.51414, 769.56016],\n",
       "  [711.43961, 758.66097, 787.91773, 770.33865],\n",
       "  [140.74551, 743.0906900000001, 144.60154, 752.0436000000001],\n",
       "  [146.52957, 743.0906900000001, 173.52185, 752.0436000000001],\n",
       "  [181.23393, 743.0906900000001, 222.36504000000002, 752.0436000000001],\n",
       "  [228.1491, 743.0906900000001, 242.28791999999999, 752.0436000000001],\n",
       "  [244.85861, 743.0906900000001, 269.92287999999996, 752.0436000000001],\n",
       "  [274.4216, 743.0906900000001, 346.40103999999997, 752.0436000000001],\n",
       "  [352.82776, 743.0906900000001, 384.31877, 752.0436000000001],\n",
       "  [388.81748999999996,\n",
       "   743.0906900000001,\n",
       "   405.52700000000004,\n",
       "   752.0436000000001],\n",
       "  [410.02572, 743.0906900000001, 451.79947999999996, 752.0436000000001],\n",
       "  [457.58355, 743.0906900000001, 480.07712000000004, 752.0436000000001],\n",
       "  [485.2185, 743.0906900000001, 520.56557, 752.0436000000001],\n",
       "  [124.03599, 752.43288, 135.60411, 762.1642899999999],\n",
       "  [140.74551, 752.43288, 180.59126, 762.1642899999999],\n",
       "  [188.30334000000002, 752.43288, 192.80205999999998, 762.1642899999999],\n",
       "  [198.58612, 752.43288, 237.7892, 762.1642899999999],\n",
       "  [246.14395, 752.43288, 285.34704, 762.1642899999999],\n",
       "  [292.41645, 752.43288, 304.62724000000003, 762.1642899999999],\n",
       "  [310.4113, 752.43288, 343.83035, 762.1642899999999],\n",
       "  [346.40103999999997, 752.43288, 388.1748, 762.1642899999999],\n",
       "  [394.60155000000003, 752.43288, 462.72492, 762.1642899999999],\n",
       "  [467.86633, 752.43288, 479.43446, 762.1642899999999],\n",
       "  [487.14653000000004, 752.43288, 498.71466, 762.1642899999999],\n",
       "  [127.24936000000001, 762.5535100000001, 178.66324, 772.28492],\n",
       "  [183.80463, 762.5535100000001, 217.86633, 772.28492],\n",
       "  [221.72236, 762.5535100000001, 239.07454, 772.28492],\n",
       "  [242.28791999999999, 762.5535100000001, 262.85346999999996, 772.28492],\n",
       "  [269.28020000000004, 762.5535100000001, 303.98458, 772.28492],\n",
       "  [305.26993000000004, 762.5535100000001, 309.76865, 772.28492],\n",
       "  [314.91002000000003, 762.5535100000001, 323.90745999999996, 772.28492],\n",
       "  [329.69153, 762.5535100000001, 347.68638000000004, 772.28492],\n",
       "  [355.39844999999997, 762.5535100000001, 417.73778, 772.28492],\n",
       "  [422.23650000000004, 762.5535100000001, 433.80463000000003, 772.28492],\n",
       "  [441.51669999999996, 762.5535100000001, 453.08483, 772.28492],\n",
       "  [461.43958000000003, 762.5535100000001, 525.06429, 772.28492],\n",
       "  [526.99226, 762.5535100000001, 531.4909799999999, 772.28492],\n",
       "  [125.96402, 773.06342, 137.53213, 782.40561],\n",
       "  [142.03085, 773.06342, 156.16967, 782.40561],\n",
       "  [164.52442, 773.06342, 169.02313999999998, 782.40561],\n",
       "  [176.73522, 773.06342, 226.86375999999998, 782.40561],\n",
       "  [233.29048999999998, 773.06342, 247.42931000000002, 782.40561],\n",
       "  [250.64269, 773.06342, 285.98973, 782.40561],\n",
       "  [291.77377, 773.06342, 342.54497, 782.40561],\n",
       "  [345.11569, 773.06342, 349.61438, 782.40561],\n",
       "  [355.39844999999997, 773.06342, 404.24165, 782.40561],\n",
       "  [404.88431, 773.06342, 409.38302999999996, 782.40561],\n",
       "  [415.16709000000003, 773.06342, 471.72236, 782.40561],\n",
       "  [478.79177, 773.06342, 490.35990000000004, 782.40561],\n",
       "  [123.39332, 783.96261, 175.44988, 792.91552],\n",
       "  [178.02057, 783.18411, 245.50127999999998, 792.91552],\n",
       "  [255.14137999999997, 783.57339, 298.84317999999996, 792.52625],\n",
       "  [302.05654999999996, 783.18411, 363.11053999999996, 792.52625],\n",
       "  [368.89461, 783.18411, 394.60155000000003, 792.13703],\n",
       "  [399.74293, 783.18411, 418.38047, 792.13703],\n",
       "  [424.80719, 783.18411, 436.37532, 792.13703],\n",
       "  [440.87404000000004, 782.79483, 462.72492, 792.13703],\n",
       "  [467.86633, 782.79483, 508.99744000000004, 791.74775],\n",
       "  [125.96402, 792.91552, 163.88174999999998, 802.25772],\n",
       "  [164.52442, 792.91552, 169.02313999999998, 802.25772],\n",
       "  [175.44988, 792.91552, 184.4473, 802.25772],\n",
       "  [190.87404, 792.91552, 210.79692, 802.25772],\n",
       "  [215.29563, 792.91552, 279.56298000000004, 802.25772],\n",
       "  [282.13367, 792.91552, 296.27249, 802.25772],\n",
       "  [303.3419, 792.91552, 314.91002000000003, 802.25772],\n",
       "  [320.69408999999996, 792.91552, 399.74293, 802.25772],\n",
       "  [402.31361999999996, 792.91552, 406.81234, 802.25772],\n",
       "  [408.09768, 792.91552, 412.59639999999996, 802.25772],\n",
       "  [125.96402, 825.2238, 204.37019, 837.68004],\n",
       "  [210.79692, 825.2238, 232.64782, 837.29076],\n",
       "  [241.64525, 824.83459, 280.20567, 837.29076],\n",
       "  [288.56041999999997, 824.83459, 299.48586, 836.51227],\n",
       "  [305.91258, 824.44531, 349.61438, 836.51227],\n",
       "  [357.96916, 824.44531, 375.96402, 836.12299],\n",
       "  [381.10539, 824.44531, 399.10024, 836.12299],\n",
       "  [405.52700000000004, 824.0560300000001, 433.16194, 835.73377],\n",
       "  [446.6581, 823.2775300000001, 483.93314999999996, 835.73377],\n",
       "  [488.43187, 823.6668099999999, 494.21594000000005, 835.34449],\n",
       "  [503.85606000000007, 823.2775300000001, 531.4909799999999, 835.34449],\n",
       "  [542.41645, 822.8882600000001, 582.2622200000001, 835.34449],\n",
       "  [125.32134, 847.41145, 153.59897999999998, 867.2635600000001],\n",
       "  [159.38303000000002, 847.41145, 199.87147, 867.2635600000001],\n",
       "  [206.94087, 847.41145, 230.71979000000002, 866.4849999999999],\n",
       "  [233.93317, 847.0221799999999, 252.57068999999998, 866.4849999999999],\n",
       "  [257.7121, 846.24368, 337.40360000000004, 866.09578],\n",
       "  [462.08227, 852.47177, 504.49871999999993, 866.09578],\n",
       "  [616.96661, 816.2709500000001, 775.06429, 887.5048800000001],\n",
       "  [628.53467, 865.31723, 685.73266, 884.3908299999999],\n",
       "  [125.96402, 885.16933, 143.95887, 896.84701],\n",
       "  [149.10026000000002, 885.16933, 231.36246, 896.84701],\n",
       "  [240.35989999999998, 885.16933, 291.13111000000004, 896.84701],\n",
       "  [307.19795999999997, 885.16933, 352.82776, 896.84701],\n",
       "  [366.32392000000004, 885.16933, 387.53214, 896.84701],\n",
       "  [389.46015, 885.16933, 395.24421, 896.84701],\n",
       "  [408.09768, 885.16933, 444.73006999999996, 896.84701],\n",
       "  [646.52956, 864.53873, 650.38562, 873.1023700000001],\n",
       "  [651.67093, 864.53873, 693.4447299999999, 873.1023700000001],\n",
       "  [700.51414, 864.53873, 713.36758, 873.1023700000001],\n",
       "  [717.8662999999999, 864.53873, 751.9280299999999, 873.1023700000001],\n",
       "  [755.78403, 864.53873, 798.2004900000001, 873.1023700000001],\n",
       "  [799.48586, 864.53873, 803.3419299999999, 873.1023700000001],\n",
       "  [647.81493, 874.2701400000001, 681.8766, 881.6659999999999],\n",
       "  [691.5167, 874.65942, 703.08483, 882.05528],\n",
       "  [710.1542400000001, 874.2701400000001, 762.85344, 882.44456],\n",
       "  [606.6837899999999, 881.6659999999999, 641.3881799999999, 891.0082],\n",
       "  [649.7429, 882.05528, 680.59129, 891.0082],\n",
       "  [683.16197, 882.44456, 687.0179800000001, 891.0082],\n",
       "  [693.4447299999999, 882.44456, 739.07453, 891.39742],\n",
       "  [745.5012800000001, 882.83378, 765.42419, 891.39742],\n",
       "  [776.99226, 883.2230599999999, 800.77124, 891.78669],\n",
       "  [654.88434, 890.61892, 674.80719, 898.40406],\n",
       "  [681.2339400000001, 890.61892, 750.0, 898.79328],\n",
       "  [621.46533, 897.23629, 674.16453, 906.9677],\n",
       "  [681.2339400000001, 898.40406, 688.94601, 906.57842],\n",
       "  [696.6580700000001, 898.79328, 739.71725, 907.7461999999999],\n",
       "  [745.5012800000001, 899.5718400000001, 782.1337000000001, 908.91397],\n",
       "  [594.4730000000001, 903.8536499999999, 656.8123099999999, 916.30983],\n",
       "  [663.23906, 904.63215, 703.08483, 916.69911],\n",
       "  [711.43961, 905.02143, 742.2879300000001, 917.08839],\n",
       "  [748.71463, 905.79993, 763.49616, 917.08839],\n",
       "  [764.13882, 905.79993, 769.92285, 917.08839],\n",
       "  [775.70695, 905.79993, 807.8406500000001, 917.86689]],\n",
       " 'tokens': ['Form ',\n",
       "  'DJ',\n",
       "  '-',\n",
       "  '307\\n',\n",
       "  'Radget ',\n",
       "  'Bureau ',\n",
       "  'No. ',\n",
       "  '43',\n",
       "  '-',\n",
       "  'R226.5\\n',\n",
       "  'proval ',\n",
       "  'Expires ',\n",
       "  'Oct. ',\n",
       "  '31',\n",
       "  ', ',\n",
       "  '1971\\n',\n",
       "  'UNITED ',\n",
       "  'STATES ',\n",
       "  'DEPARTMENT ',\n",
       "  'OF ',\n",
       "  'JUSTICE\\n',\n",
       "  'WASHINGTON',\n",
       "  ', ',\n",
       "  'D.C. ',\n",
       "  '20530\\n',\n",
       "  'AMENDMENT ',\n",
       "  'TO ',\n",
       "  'REGISTRATION ',\n",
       "  'STATEMENT\\n',\n",
       "  '1\\n',\n",
       "  'Pursuant ',\n",
       "  'to ',\n",
       "  'the ',\n",
       "  'Foreign ',\n",
       "  'Agents\\n',\n",
       "  'Registration ',\n",
       "  'Act ',\n",
       "  'of ',\n",
       "  '1938',\n",
       "  ', ',\n",
       "  'as ',\n",
       "  'amended',\n",
       "  '.\\n',\n",
       "  '!\\n',\n",
       "  '1. ',\n",
       "  'Name ',\n",
       "  'of ',\n",
       "  'Registrant\\n',\n",
       "  '2. ',\n",
       "  'Registration ',\n",
       "  'No.\\n',\n",
       "  'OFFICE ',\n",
       "  'OF ',\n",
       "  'TURKISH\\n',\n",
       "  'CYPRIOT ',\n",
       "  'COMMUNITY\\n',\n",
       "  '2619\\n',\n",
       "  '3. ',\n",
       "  'This ',\n",
       "  'amendment ',\n",
       "  'is ',\n",
       "  'filed ',\n",
       "  'to ',\n",
       "  'accomplish ',\n",
       "  'the ',\n",
       "  'following ',\n",
       "  'indicated ',\n",
       "  'purpose ',\n",
       "  'or ',\n",
       "  'purposes',\n",
       "  ':\\n',\n",
       "  'To ',\n",
       "  'correct ',\n",
       "  'a ',\n",
       "  'deficiency ',\n",
       "  'in\\n',\n",
       "  '☐ ',\n",
       "  'To ',\n",
       "  'give ',\n",
       "  'a ',\n",
       "  '10',\n",
       "  '-',\n",
       "  'day ',\n",
       "  'notice ',\n",
       "  'of ',\n",
       "  'a ',\n",
       "  'change ',\n",
       "  'in ',\n",
       "  'infor-\\n',\n",
       "  'mation ',\n",
       "  'as ',\n",
       "  'required ',\n",
       "  'by ',\n",
       "  'Section ',\n",
       "  '2',\n",
       "  '(',\n",
       "  'b',\n",
       "  ') ',\n",
       "  'of ',\n",
       "  'the ',\n",
       "  'Act',\n",
       "  '.\\n',\n",
       "  'Initial ',\n",
       "  'Statement\\n',\n",
       "  '☑ ',\n",
       "  'Supplemental ',\n",
       "  'Statement\\n',\n",
       "  'for ',\n",
       "  'April ',\n",
       "  '16',\n",
       "  ', ',\n",
       "  '1976\\n',\n",
       "  '| ',\n",
       "  'Other ',\n",
       "  'purpose ',\n",
       "  '(',\n",
       "  'specify',\n",
       "  ') ',\n",
       "  'Change ',\n",
       "  'of ',\n",
       "  'address\\n',\n",
       "  'To ',\n",
       "  'give ',\n",
       "  'notice ',\n",
       "  'of ',\n",
       "  'change ',\n",
       "  'in ',\n",
       "  'an\\n',\n",
       "  'exhibit ',\n",
       "  'previously ',\n",
       "  'filed',\n",
       "  '.\\n',\n",
       "  '4. ',\n",
       "  'If ',\n",
       "  'this ',\n",
       "  'amendment ',\n",
       "  'requires ',\n",
       "  'the ',\n",
       "  'filing ',\n",
       "  'of ',\n",
       "  'a ',\n",
       "  'document ',\n",
       "  'or ',\n",
       "  'documents',\n",
       "  ', ',\n",
       "  'please ',\n",
       "  'list-\\n',\n",
       "  '(',\n",
       "  'a',\n",
       "  ') ',\n",
       "  'Article ',\n",
       "  'Chicago ',\n",
       "  'Daily ',\n",
       "  'News',\n",
       "  ', ',\n",
       "  'Friday',\n",
       "  ', ',\n",
       "  'March ',\n",
       "  '12',\n",
       "  ', ',\n",
       "  '1976\\n',\n",
       "  '(',\n",
       "  'b',\n",
       "  ') ',\n",
       "  'Article ',\n",
       "  'Times ',\n",
       "  'Herald ',\n",
       "  'Record ',\n",
       "  'Middletown',\n",
       "  ', ',\n",
       "  'N.Y. ',\n",
       "  'March ',\n",
       "  '27',\n",
       "  ', ',\n",
       "  '1976\\n',\n",
       "  '(',\n",
       "  'c',\n",
       "  ') ',\n",
       "  'Amendment ',\n",
       "  'to ',\n",
       "  'Item ',\n",
       "  '12 ',\n",
       "  'of ',\n",
       "  'Amended ',\n",
       "  'Supplemental ',\n",
       "  'Statement ',\n",
       "  'for ',\n",
       "  'period ',\n",
       "  'ending\\n',\n",
       "  'April ',\n",
       "  '16',\n",
       "  ', ',\n",
       "  '1976 ',\n",
       "  'filed ',\n",
       "  'October ',\n",
       "  '2',\n",
       "  ', ',\n",
       "  '1976\\n',\n",
       "  '(',\n",
       "  'a',\n",
       "  ') ',\n",
       "  'Dissemination ',\n",
       "  'Reports',\n",
       "  '5. ',\n",
       "  'Each ',\n",
       "  'item ',\n",
       "  'thecked ',\n",
       "  'above \\n',\n",
       "  'must ',\n",
       "  'be ',\n",
       "  'explained ',\n",
       "  'below ',\n",
       "  'in ',\n",
       "  'full ',\n",
       "  'detail ',\n",
       "  'together ',\n",
       "  'with',\n",
       "  ', ',\n",
       "  'where ',\n",
       "  'appropriate',\n",
       "  ',\\n',\n",
       "  'specific ',\n",
       "  'reference ',\n",
       "  'to ',\n",
       "  'and ',\n",
       "  'identity ',\n",
       "  'of ',\n",
       "  'the ',\n",
       "  'item ',\n",
       "  'in ',\n",
       "  'the ',\n",
       "  'registration ',\n",
       "  'statement ',\n",
       "  'to ',\n",
       "  'which ',\n",
       "  'it ',\n",
       "  'pertains',\n",
       "  '. ',\n",
       "  'If\\n',\n",
       "  'more ',\n",
       "  'space ',\n",
       "  'is ',\n",
       "  'needed',\n",
       "  ', ',\n",
       "  'full ',\n",
       "  'size ',\n",
       "  'insert ',\n",
       "  'sheets ',\n",
       "  'may ',\n",
       "  'be ',\n",
       "  'used',\n",
       "  '.\\n',\n",
       "  'Item ',\n",
       "  '12 ',\n",
       "  'amended ',\n",
       "  'as ',\n",
       "  'per ',\n",
       "  'insert ',\n",
       "  'page ',\n",
       "  '1\\n',\n",
       "  \"Registrant's \",\n",
       "  'address ',\n",
       "  'changed ',\n",
       "  'to',\n",
       "  ':\\n',\n",
       "  'Office ',\n",
       "  'of ',\n",
       "  'Turkish ',\n",
       "  'Cypriot ',\n",
       "  'Community\\n',\n",
       "  '622 ',\n",
       "  'Third ',\n",
       "  'Avenue',\n",
       "  ', ',\n",
       "  '33rd ',\n",
       "  'Floor\\n',\n",
       "  'New ',\n",
       "  'York',\n",
       "  ', ',\n",
       "  'New ',\n",
       "  'York\\n',\n",
       "  'The ',\n",
       "  'undersigned ',\n",
       "  'swear',\n",
       "  '(',\n",
       "  's',\n",
       "  ') ',\n",
       "  'or ',\n",
       "  'affirm',\n",
       "  '(',\n",
       "  's',\n",
       "  ') ',\n",
       "  'that ',\n",
       "  'he ',\n",
       "  'has ',\n",
       "  'they ',\n",
       "  'have',\n",
       "  ') ',\n",
       "  'read ',\n",
       "  'the ',\n",
       "  'information ',\n",
       "  'set ',\n",
       "  'forth ',\n",
       "  'in ',\n",
       "  'this\\n',\n",
       "  'amendment ',\n",
       "  'and ',\n",
       "  'that ',\n",
       "  'he ',\n",
       "  'is ',\n",
       "  '(',\n",
       "  'they ',\n",
       "  'are',\n",
       "  ') ',\n",
       "  'familiar ',\n",
       "  'with ',\n",
       "  'the ',\n",
       "  'contents ',\n",
       "  'thereof ',\n",
       "  'and ',\n",
       "  'that ',\n",
       "  'such ',\n",
       "  'contents ',\n",
       "  'are ',\n",
       "  'in ',\n",
       "  'their\\n',\n",
       "  'entirety ',\n",
       "  'true ',\n",
       "  'and ',\n",
       "  'accurate ',\n",
       "  'to ',\n",
       "  'the ',\n",
       "  'best ',\n",
       "  'of ',\n",
       "  'his ',\n",
       "  '(',\n",
       "  'their',\n",
       "  ') ',\n",
       "  'knowledge ',\n",
       "  'and ',\n",
       "  'belief',\n",
       "  '.\\n',\n",
       "  'Prameny\\n',\n",
       "  'Nail ',\n",
       "  'Atalay',\n",
       "  ', ',\n",
       "  'Director\\n',\n",
       "  '(',\n",
       "  'Both ',\n",
       "  'copies ',\n",
       "  'of ',\n",
       "  'this ',\n",
       "  'amendment ',\n",
       "  'shall ',\n",
       "  'be ',\n",
       "  'signed ',\n",
       "  'and ',\n",
       "  'sworn\\n',\n",
       "  'to ',\n",
       "  'before ',\n",
       "  'a ',\n",
       "  'notary ',\n",
       "  'public ',\n",
       "  'or ',\n",
       "  'other ',\n",
       "  'person ',\n",
       "  'authorized ',\n",
       "  'to ',\n",
       "  'ad-\\n',\n",
       "  'minister ',\n",
       "  'oaths ',\n",
       "  'by ',\n",
       "  'the ',\n",
       "  'agent',\n",
       "  ', ',\n",
       "  'if ',\n",
       "  'the ',\n",
       "  'registrant ',\n",
       "  'is ',\n",
       "  'an ',\n",
       "  'individual',\n",
       "  ',\\n',\n",
       "  'or ',\n",
       "  'by ',\n",
       "  'a ',\n",
       "  'majority ',\n",
       "  'of ',\n",
       "  'those ',\n",
       "  'partners',\n",
       "  ', ',\n",
       "  'officers',\n",
       "  ', ',\n",
       "  'directors ',\n",
       "  'or\\n',\n",
       "  'persons ',\n",
       "  'performing ',\n",
       "  'similar ',\n",
       "  'functions ',\n",
       "  'who ',\n",
       "  'are ',\n",
       "  'in ',\n",
       "  'the ',\n",
       "  'United\\n',\n",
       "  'States',\n",
       "  ', ',\n",
       "  'if ',\n",
       "  'the ',\n",
       "  'registrant ',\n",
       "  'is ',\n",
       "  'an ',\n",
       "  'organization',\n",
       "  '.',\n",
       "  ')\\n',\n",
       "  'Subscribed ',\n",
       "  'and ',\n",
       "  'sworn ',\n",
       "  'to ',\n",
       "  'before ',\n",
       "  'me ',\n",
       "  'at ',\n",
       "  'New ',\n",
       "  'York',\n",
       "  ', ',\n",
       "  'New ',\n",
       "  'York\\n',\n",
       "  'this ',\n",
       "  '28th ',\n",
       "  'day ',\n",
       "  'of ',\n",
       "  'December\\n',\n",
       "  '1976\\n',\n",
       "  'Pobla\\n',\n",
       "  '✓OSEPH\\n',\n",
       "  'My ',\n",
       "  'commission ',\n",
       "  'expires ',\n",
       "  'March ',\n",
       "  '31',\n",
       "  ', ',\n",
       "  '1977\\n',\n",
       "  '(',\n",
       "  'Noflry ',\n",
       "  'or ',\n",
       "  'other ',\n",
       "  'officer',\n",
       "  ')\\n',\n",
       "  'KOSEPH ',\n",
       "  'P. ',\n",
       "  'ALBANESE\\n',\n",
       "  'Notary ',\n",
       "  'Public',\n",
       "  ', ',\n",
       "  'Stof ',\n",
       "  'New ',\n",
       "  'York\\n',\n",
       "  'No. ',\n",
       "  '41-0067900\\n',\n",
       "  'Qualified ',\n",
       "  'in ',\n",
       "  'Gems ',\n",
       "  'County\\n',\n",
       "  'Commission ',\n",
       "  'Expires ',\n",
       "  'March ',\n",
       "  '30',\n",
       "  ', ',\n",
       "  '1972\\n'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  11,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'images': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1696x2800>,\n",
       " 'image_path': 'VT2/vrdu/registration-form/main/pngs/19770101_Representative of the Turkish Republic of Northern Cyprus_Amendment_Amendment/page_1.png',\n",
       " 'image_size': {'height': 2569, 'width': 1556}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_unmapped[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a8bc44-bdf9-4578-b1d9-a729339172ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "# we'll use the Auto API here - it will load LayoutLMv3Processor behind the scenes,\n",
    "# based on the checkpoint we provide from the hub\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04cd1377-97ba-4072-b6ad-a3589283ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.features import ClassLabel\n",
    "\n",
    "features = train_dataset_unmapped.features\n",
    "column_names = train_dataset_unmapped.column_names\n",
    "image_column_name = \"images\"\n",
    "text_column_name = \"tokens\"\n",
    "boxes_column_name = \"bboxes\"\n",
    "label_column_name = \"ner_tags\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9755cec9-4112-4fd7-bf4a-a224c615df12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-FILE_DATE',\n",
       " 'I-FILE_DATE',\n",
       " 'B-FOREIGN_PRINCIPLE_NAME',\n",
       " 'I-FOREIGN_PRINCIPLE_NAME',\n",
       " 'B-REGISTRANT_NAME',\n",
       " 'I-REGISTRANT_NAME',\n",
       " 'B-REGISTRATION_NUM',\n",
       " 'I-REGISTRATION_NUM',\n",
       " 'B-SIGNER_NAME',\n",
       " 'I-SIGNER_NAME',\n",
       " 'B-SIGNER_TITLE',\n",
       " 'I-SIGNER_TITLE']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a866a4c-f034-4e62-a641-beb9fdba75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-FILE_DATE',\n",
       " 2: 'I-FILE_DATE',\n",
       " 3: 'B-FOREIGN_PRINCIPLE_NAME',\n",
       " 4: 'I-FOREIGN_PRINCIPLE_NAME',\n",
       " 5: 'B-REGISTRANT_NAME',\n",
       " 6: 'I-REGISTRANT_NAME',\n",
       " 7: 'B-REGISTRATION_NUM',\n",
       " 8: 'I-REGISTRATION_NUM',\n",
       " 9: 'B-SIGNER_NAME',\n",
       " 10: 'I-SIGNER_NAME',\n",
       " 11: 'B-SIGNER_TITLE',\n",
       " 12: 'I-SIGNER_TITLE'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6b6569a-c064-45da-b985-d91170ef9eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_examples(examples):\n",
    "    images = examples[image_column_name]\n",
    "    words = examples[text_column_name]\n",
    "    boxes = examples[boxes_column_name]\n",
    "    word_labels = examples[label_column_name]\n",
    "\n",
    "    # Process the data using the processor\n",
    "    encoding = processor(\n",
    "        images,\n",
    "        words,\n",
    "        boxes=boxes,\n",
    "        word_labels=word_labels,\n",
    "        truncation=True, \n",
    "        stride =128,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    # Extract overflow mappings\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "    overflow_to_sample_mapping = encoding.pop('overflow_to_sample_mapping')\n",
    "\n",
    "    output = {**encoding, \"offset_mapping\": offset_mapping}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61cec49-2267-43a2-959f-f742c77717e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████| 20/20 [00:02<00:00,  9.69 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██| 44/44 [00:00<00:00, 931.62 examples/s]\n",
      "Map: 100%|█████████████████████████████| 205/205 [00:27<00:00,  7.47 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█| 650/650 [00:00<00:00, 724.89 examples/s\n"
     ]
    }
   ],
   "source": [
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
    "import numpy as np\n",
    "\n",
    "# we need to define custom features for `set_format` (used later on) to work properly\n",
    "features = Features({\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype='int64')),\n",
    "    'offset_mapping': Sequence(feature=Sequence(Value(dtype='int64'))),  # Offset mapping for metrics\n",
    "})\n",
    "\n",
    "train_dataset = train_dataset_unmapped.map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"pixel_values\", \"input_ids\", \"attention_mask\", \"bbox\", \"labels\"]\n",
    ")\n",
    "train_dataset.save_to_disk(fr\"{path_extraction_folder}/train.hf\")\n",
    "\n",
    "valid_dataset = valid_dataset_unmapped.map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")\n",
    "valid_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"pixel_values\", \"input_ids\", \"attention_mask\", \"bbox\", \"labels\"]\n",
    ")\n",
    "valid_dataset.save_to_disk(fr\"{path_extraction_folder}/valid.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72343bf5-04bc-4a6d-8253-837d640a8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 263\n",
      "})\n",
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 650\n",
      "})\n",
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 44\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "test_dataset = load_from_disk(fr\"{path_extraction_folder_test}/test.hf\")\n",
    "valid_dataset = load_from_disk(fr\"{path_extraction_folder}/valid.hf\")\n",
    "train_dataset = load_from_disk(fr\"{path_extraction_folder}/train.hf\")\n",
    "\n",
    "# Optionally, you can print to verify the datasets are loaded correctly\n",
    "print(test_dataset)\n",
    "print(valid_dataset)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea8db24-a60f-4fb6-ba39-804313f94215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 650\n",
      "})\n",
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 44\n",
      "})\n",
      "Dataset({\n",
      "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
      "    num_rows: 263\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "valid_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"pixel_values\", \"input_ids\", \"attention_mask\", \"bbox\", \"labels\"]  # Exclude offset_mapping\n",
    ")\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"pixel_values\", \"input_ids\", \"attention_mask\", \"bbox\", \"labels\"]  # Exclude offset_mapping\n",
    ")\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"pixel_values\", \"input_ids\", \"attention_mask\", \"bbox\", \"labels\"]  # Exclude offset_mapping\n",
    ")\n",
    "\n",
    "# Optionally, you can print to verify the datasets are loaded correctly\n",
    "\n",
    "print(valid_dataset)\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb92a7ab-2c9c-4f46-92bf-ca57680d4892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
       "    num_rows: 44\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd953966-82c7-463e-97e6-809a2b8631de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Form  DJ - 307\\n Radget  Bureau  No.  43 - R226.5\\n proval  Expires  Oct.  31 ,  1971\\n UNITED  STATES  DEPARTMENT  OF  JUSTICE\\n WASHINGTON ,  D.C.  20530\\n AMENDMENT  TO  REGISTRATION  STATEMENT\\n 1\\n Pursuant  to  the  Foreign  Agents\\n Registration  Act  of  1938 ,  as  amended .\\n !\\n 1.  Name  of  Registrant\\n 2.  Registration  No.\\n OFFICE  OF  TURKISH\\n CYPRIOT  COMMUNITY\\n 2619\\n 3.  This  amendment  is  filed  to  accomplish  the  following  indicated  purpose  or  purposes :\\n To  correct  a  deficiency  in\\n ☐  To  give  a  10 - day  notice  of  a  change  in  infor-\\n mation  as  required  by  Section  2 ( b )  of  the  Act .\\n Initial  Statement\\n ☑  Supplemental  Statement\\n for  April  16 ,  1976\\n |  Other  purpose  ( specify )  Change  of  address\\n To  give  notice  of  change  in  an\\n exhibit  previously  filed .\\n 4.  If  this  amendment  requires  the  filing  of  a  document  or  documents ,  please  list-\\n ( a )  Article  Chicago  Daily  News ,  Friday ,  March  12 ,  1976\\n ( b )  Article  Times  Herald  Record  Middletown ,  N.Y.  March  27 ,  1976\\n ( c )  Amendment  to  Item  12  of  Amended  Supplemental  Statement  for  period  ending\\n April  16 ,  1976  filed  October  2 ,  1976\\n ( a )  Dissemination  Reports 5.  Each  item  thecked  above \\n must  be  explained  below  in  full  detail  together  with ,  where  appropriate ,\\n specific  reference  to  and  identity  of  the  item  in  the  registration  statement  to  which  it  pertains .  If\\n more  space  is  needed ,  full  size </s>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train_dataset[0]\n",
    "processor.tokenizer.decode(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40b813af-510c-412f-8805-6af7531c9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66d048c8-d1ba-42ee-97d0-92c3cb64bde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 224, 224])\n",
      "input_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "bbox torch.Size([512, 4])\n",
      "labels torch.Size([512])\n",
      "offset_mapping torch.Size([512, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example = train_dataset[0]\n",
    "for k,v in example.items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50762986-e4c5-45eb-a45f-21744ab410b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pixel_values', 'input_ids', 'attention_mask', 'bbox', 'labels', 'offset_mapping'],\n",
       "    num_rows: 650\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3592c75b-fd09-4070-bbf9-3a55ab6aab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> OMB  NO .  1105-0013\\n U.S.  Department  of  Justice\\n Washington ,  DC  20530\\n Short - Form  Registration  Statement\\n Pursuant  to  the  Foreign  Agents  Registration\\n Act  of  1938 ,  as  amended\\n Each  partner ,  officer ,  director ,  associate ,  employee ,  and  agent  of  a  registrant  is  required  to  file  a  short  form  registration  statement  unless  he  engages  in  no  activities\\n in  furtherance  of  the  interests  of  the  registrant's  foreign  principal  or  unless  the  services  he  renders  to  the  registrant  are  in  a  secretarial ,  clerical ,  or  in  a  related  or\\n similar  capacity .\\n Privacy  Act  Statement .  Every  registration  statement ,  short  form  registration  statement ,  supplemental  statement ,  exhibit ,  amendment ,  copy  of  informational\\n materials  or  other  document  or  information  filed  with  the  Attorney  General  under  this  Act  is  a  public  record  open  to  public  examination ,  inspection  and  copying\\n during  the  posted  business  hours  of  the  Registration  Unit  in  Washington ,  D.C.  One  copy  of  every  such  document ,  other  than  informational  materials ,  is\\n automatically  provided  to  the  Secretary  of  State  pursuant  to  Section  6 ( b )  of  the  Act ,  and  copies  of  any  and  all  documents  are  routinely  made  available  to  other\\n agencies ,  departments  and  Congress  pursuant  to  Section  6 ( c )  of  the  Act .  The  Attorney  General  also  transmits  a  semi - annual  report  to  Congress  on  the\\n Administration  of  the  Act  which  lists  the  names  of  all  agents  registered  under  Act  and  the  foreign  principals  they  represent .  This  report  is  available  to  the\\n public :  Finally ,  the  Attorney</s>\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(valid_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6683f2f0-9f9f-4261-a5a0-b7fda0cffe21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> -100\n",
      " Form 0\n",
      "  -100\n",
      " DJ 0\n",
      " - 0\n",
      " 307 0\n",
      "\n",
      " -100\n",
      " Rad 0\n",
      "get -100\n",
      "  -100\n",
      " Bureau 0\n",
      "  -100\n",
      " No 0\n",
      ". -100\n",
      "  -100\n",
      " 43 0\n",
      " - 0\n",
      " R 0\n",
      "226 -100\n",
      ". -100\n",
      "5 -100\n",
      "\n",
      " -100\n",
      " prov 0\n",
      "al -100\n",
      "  -100\n",
      " Exp 0\n",
      "ires -100\n",
      "  -100\n",
      " Oct 0\n",
      ". -100\n",
      "  -100\n",
      " 31 0\n",
      " , 0\n",
      "  -100\n",
      " 1971 0\n",
      "\n",
      " -100\n",
      " UNITED 0\n",
      "  -100\n",
      " STATES 0\n",
      "  -100\n",
      " DE 0\n",
      "PART -100\n",
      "MENT -100\n",
      "  -100\n",
      " OF 0\n",
      "  -100\n",
      " JUSTICE 0\n",
      "\n",
      " -100\n",
      " W 0\n",
      "ASHINGTON -100\n",
      " , 0\n",
      "  -100\n",
      " D 0\n",
      ". -100\n",
      "C -100\n",
      ". -100\n",
      "  -100\n",
      " 205 0\n",
      "30 -100\n",
      "\n",
      " -100\n",
      " AM 0\n",
      "END -100\n",
      "MENT -100\n",
      "  -100\n",
      " TO 0\n",
      "  -100\n",
      " REG 0\n",
      "IS -100\n",
      "TR -100\n",
      "ATION -100\n",
      "  -100\n",
      " STAT 0\n",
      "EMENT -100\n",
      "\n",
      " -100\n",
      " 1 0\n",
      "\n",
      " -100\n",
      " Purs 0\n",
      "u -100\n",
      "ant -100\n",
      "  -100\n",
      " to 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " Foreign 0\n",
      "  -100\n",
      " Agents 0\n",
      "\n",
      " -100\n",
      " Registration 0\n",
      "  -100\n",
      " Act 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " 1938 0\n",
      " , 0\n",
      "  -100\n",
      " as 0\n",
      "  -100\n",
      " amended 0\n",
      " . 0\n",
      "\n",
      " -100\n",
      " ! 0\n",
      "\n",
      " -100\n",
      " 1 0\n",
      ". -100\n",
      "  -100\n",
      " Name 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " Regist 0\n",
      "rant -100\n",
      "\n",
      " -100\n",
      " 2 0\n",
      ". -100\n",
      "  -100\n",
      " Registration 0\n",
      "  -100\n",
      " No 0\n",
      ". -100\n",
      "\n",
      " -100\n",
      " OFF 5\n",
      "ICE -100\n",
      "  -100\n",
      " OF 6\n",
      "  -100\n",
      " T 6\n",
      "UR -100\n",
      "K -100\n",
      "ISH -100\n",
      "\n",
      " -100\n",
      " CY 6\n",
      "PR -100\n",
      "I -100\n",
      "OT -100\n",
      "  -100\n",
      " COMMUN 6\n",
      "ITY -100\n",
      "\n",
      " -100\n",
      " 26 7\n",
      "19 -100\n",
      "\n",
      " -100\n",
      " 3 0\n",
      ". -100\n",
      "  -100\n",
      " This 0\n",
      "  -100\n",
      " amendment 0\n",
      "  -100\n",
      " is 0\n",
      "  -100\n",
      " filed 0\n",
      "  -100\n",
      " to 0\n",
      "  -100\n",
      " accomplish 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " following 0\n",
      "  -100\n",
      " indicated 0\n",
      "  -100\n",
      " purpose 0\n",
      "  -100\n",
      " or 0\n",
      "  -100\n",
      " purposes 0\n",
      " : 0\n",
      "\n",
      " -100\n",
      " To 0\n",
      "  -100\n",
      " correct 0\n",
      "  -100\n",
      " a 0\n",
      "  -100\n",
      " deficiency 0\n",
      "  -100\n",
      " in 0\n",
      "\n",
      " -100\n",
      " � 0\n",
      "� 0\n",
      "  -100\n",
      " To 0\n",
      "  -100\n",
      " give 0\n",
      "  -100\n",
      " a 0\n",
      "  -100\n",
      " 10 0\n",
      " - 0\n",
      " day 0\n",
      "  -100\n",
      " notice 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " a 0\n",
      "  -100\n",
      " change 0\n",
      "  -100\n",
      " in 0\n",
      "  -100\n",
      " inf 0\n",
      "or -100\n",
      "- -100\n",
      "\n",
      " -100\n",
      " m 0\n",
      "ation -100\n",
      "  -100\n",
      " as 0\n",
      "  -100\n",
      " required 0\n",
      "  -100\n",
      " by 0\n",
      "  -100\n",
      " Section 0\n",
      "  -100\n",
      " 2 0\n",
      " ( 0\n",
      " b 0\n",
      " ) 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " Act 0\n",
      " . 0\n",
      "\n",
      " -100\n",
      " Initial 0\n",
      "  -100\n",
      " Statement 0\n",
      "\n",
      " -100\n",
      " � 0\n",
      "� 0\n",
      "  -100\n",
      " Supplemental 0\n",
      "  -100\n",
      " Statement 0\n",
      "\n",
      " -100\n",
      " for 0\n",
      "  -100\n",
      " April 0\n",
      "  -100\n",
      " 16 0\n",
      " , 0\n",
      "  -100\n",
      " 1976 0\n",
      "\n",
      " -100\n",
      " | 0\n",
      "  -100\n",
      " Other 0\n",
      "  -100\n",
      " purpose 0\n",
      "  -100\n",
      " ( 0\n",
      " specify 0\n",
      " ) 0\n",
      "  -100\n",
      " Change 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " address 0\n",
      "\n",
      " -100\n",
      " To 0\n",
      "  -100\n",
      " give 0\n",
      "  -100\n",
      " notice 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " change 0\n",
      "  -100\n",
      " in 0\n",
      "  -100\n",
      " an 0\n",
      "\n",
      " -100\n",
      " exhibit 0\n",
      "  -100\n",
      " previously 0\n",
      "  -100\n",
      " filed 0\n",
      " . 0\n",
      "\n",
      " -100\n",
      " 4 0\n",
      ". -100\n",
      "  -100\n",
      " If 0\n",
      "  -100\n",
      " this 0\n",
      "  -100\n",
      " amendment 0\n",
      "  -100\n",
      " requires 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " filing 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " a 0\n",
      "  -100\n",
      " document 0\n",
      "  -100\n",
      " or 0\n",
      "  -100\n",
      " documents 0\n",
      " , 0\n",
      "  -100\n",
      " please 0\n",
      "  -100\n",
      " list 0\n",
      "- -100\n",
      "\n",
      " -100\n",
      " ( 0\n",
      " a 0\n",
      " ) 0\n",
      "  -100\n",
      " Article 0\n",
      "  -100\n",
      " Chicago 0\n",
      "  -100\n",
      " Daily 0\n",
      "  -100\n",
      " News 0\n",
      " , 0\n",
      "  -100\n",
      " Friday 0\n",
      " , 0\n",
      "  -100\n",
      " March 0\n",
      "  -100\n",
      " 12 0\n",
      " , 0\n",
      "  -100\n",
      " 1976 0\n",
      "\n",
      " -100\n",
      " ( 0\n",
      " b 0\n",
      " ) 0\n",
      "  -100\n",
      " Article 0\n",
      "  -100\n",
      " Times 0\n",
      "  -100\n",
      " Herald 0\n",
      "  -100\n",
      " Record 0\n",
      "  -100\n",
      " M 0\n",
      "idd -100\n",
      "let -100\n",
      "own -100\n",
      " , 0\n",
      "  -100\n",
      " N 0\n",
      ". -100\n",
      "Y -100\n",
      ". -100\n",
      "  -100\n",
      " March 0\n",
      "  -100\n",
      " 27 0\n",
      " , 0\n",
      "  -100\n",
      " 1976 0\n",
      "\n",
      " -100\n",
      " ( 0\n",
      " c 0\n",
      " ) 0\n",
      "  -100\n",
      " Amendment 0\n",
      "  -100\n",
      " to 0\n",
      "  -100\n",
      " Item 0\n",
      "  -100\n",
      " 12 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " Am 0\n",
      "ended -100\n",
      "  -100\n",
      " Supplemental 0\n",
      "  -100\n",
      " Statement 0\n",
      "  -100\n",
      " for 0\n",
      "  -100\n",
      " period 0\n",
      "  -100\n",
      " ending 0\n",
      "\n",
      " -100\n",
      " April 0\n",
      "  -100\n",
      " 16 0\n",
      " , 0\n",
      "  -100\n",
      " 1976 0\n",
      "  -100\n",
      " filed 0\n",
      "  -100\n",
      " October 0\n",
      "  -100\n",
      " 2 0\n",
      " , 0\n",
      "  -100\n",
      " 1976 0\n",
      "\n",
      " -100\n",
      " ( 0\n",
      " a 0\n",
      " ) 0\n",
      "  -100\n",
      " Dis 0\n",
      "se -100\n",
      "mination -100\n",
      "  -100\n",
      " Reports 0\n",
      " 5 0\n",
      ". -100\n",
      "  -100\n",
      " Each 0\n",
      "  -100\n",
      " item 0\n",
      "  -100\n",
      " the 0\n",
      "ck -100\n",
      "ed -100\n",
      "  -100\n",
      " above 0\n",
      "  -100\n",
      "\n",
      " -100\n",
      " must 0\n",
      "  -100\n",
      " be 0\n",
      "  -100\n",
      " explained 0\n",
      "  -100\n",
      " below 0\n",
      "  -100\n",
      " in 0\n",
      "  -100\n",
      " full 0\n",
      "  -100\n",
      " detail 0\n",
      "  -100\n",
      " together 0\n",
      "  -100\n",
      " with 0\n",
      " , 0\n",
      "  -100\n",
      " where 0\n",
      "  -100\n",
      " appropriate 0\n",
      " , 0\n",
      "\n",
      " -100\n",
      " specific 0\n",
      "  -100\n",
      " reference 0\n",
      "  -100\n",
      " to 0\n",
      "  -100\n",
      " and 0\n",
      "  -100\n",
      " identity 0\n",
      "  -100\n",
      " of 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " item 0\n",
      "  -100\n",
      " in 0\n",
      "  -100\n",
      " the 0\n",
      "  -100\n",
      " registration 0\n",
      "  -100\n",
      " statement 0\n",
      "  -100\n",
      " to 0\n",
      "  -100\n",
      " which 0\n",
      "  -100\n",
      " it 0\n",
      "  -100\n",
      " per 0\n",
      "tains -100\n",
      " . 0\n",
      "  -100\n",
      " If 0\n",
      "\n",
      " -100\n",
      " more 0\n",
      "  -100\n",
      " space 0\n",
      "  -100\n",
      " is 0\n",
      "  -100\n",
      " needed 0\n",
      " , 0\n",
      "  -100\n",
      " full 0\n",
      "  -100\n",
      " size 0\n",
      "  -100\n",
      "</s> -100\n"
     ]
    }
   ],
   "source": [
    "for id, label in zip(train_dataset[0][\"input_ids\"], train_dataset[0][\"labels\"]):\n",
    "  print(processor.tokenizer.decode([id]), label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d087c79a-acdc-4e11-a3fd-577d262a329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load the metric using the updated method\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "return_entity_level_metrics = False\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }\n",
    "\n",
    "def compute_metrics_with_stride(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Retrieve offset_mapping from eval_dataset\n",
    "    offset_mapping = trainer.eval_dataset[\"offset_mapping\"]\n",
    "\n",
    "    true_predictions, true_labels = [], []\n",
    "\n",
    "    for i, (pred_chunk, label_chunk, offsets) in enumerate(zip(predictions, labels, offset_mapping)):\n",
    "        non_overlap_indices = [idx for idx, offset in enumerate(offsets) if offset[0] == 0]\n",
    "\n",
    "        filtered_preds = [pred_chunk[idx] for idx in non_overlap_indices]\n",
    "        filtered_labels = [label_chunk[idx] for idx in non_overlap_indices]\n",
    "\n",
    "        chunk_predictions = [\n",
    "            label_list[p] for (p, l) in zip(filtered_preds, filtered_labels) if l != -100\n",
    "        ]\n",
    "        chunk_labels = [\n",
    "            label_list[l] for (p, l) in zip(filtered_preds, filtered_labels) if l != -100\n",
    "        ]\n",
    "\n",
    "        if chunk_predictions and chunk_labels:\n",
    "            true_predictions.append(chunk_predictions)\n",
    "            true_labels.append(chunk_labels)\n",
    "\n",
    "    if not true_predictions or not true_labels:\n",
    "        print(\"Warning: No valid predictions or labels found.\")\n",
    "        true_predictions = [[]]\n",
    "        true_labels = [[]]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ad173e1-4caf-4add-9aa8-a1ebf018907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3ForTokenClassification\n",
    "\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\",\n",
    "                                                         id2label=id2label,\n",
    "                                                         label2id=label2id)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e71e26d7-6cbb-4b77-a4fb-8e7e8e72310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=fr\"{path_extraction_folder}/test\",\n",
    "    max_steps=1000,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,  \n",
    "    learning_rate=3e-5,  # Adjusted learning rate for faster convergence without overshooting\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,  \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model=\"f1\",  \n",
    "    weight_decay=0.01,  # Regularization to prevent overfitting \n",
    "    warmup_steps=500,  # Warm-up phase for smoother learning rate scaling\n",
    "    gradient_accumulation_steps=2,  \n",
    "    save_steps=1000,  \n",
    "    fp16=True,  # Enable mixed precision training if your GPU supports it\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "750adb06-1086-47ce-a746-873b0130a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics_with_stride,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed8ac2cd-4085-4ad3-aad2-590d2b7385d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/transformers/modeling_utils.py:1141: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 13:34, Epoch 333/334]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.123947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116207</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.044260</td>\n",
       "      <td>0.983317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135310</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.104634</td>\n",
       "      <td>0.983917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140355</td>\n",
       "      <td>0.300676</td>\n",
       "      <td>0.156140</td>\n",
       "      <td>0.205543</td>\n",
       "      <td>0.984123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.134260</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.261084</td>\n",
       "      <td>0.985209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.152745</td>\n",
       "      <td>0.505682</td>\n",
       "      <td>0.156140</td>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.984130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>0.237381</td>\n",
       "      <td>0.984023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.170069</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.223464</td>\n",
       "      <td>0.984030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.532051</td>\n",
       "      <td>0.145614</td>\n",
       "      <td>0.228650</td>\n",
       "      <td>0.984023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.172071</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.145614</td>\n",
       "      <td>0.227709</td>\n",
       "      <td>0.984023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.12763957911729812, metrics={'train_runtime': 816.4504, 'train_samples_per_second': 19.597, 'train_steps_per_second': 1.225, 'total_flos': 3893383214026752.0, 'train_loss': 0.12763957911729812, 'epoch': 333.3333333333333})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47eb4d3b-eb56-40ac-a313-0df7fcb63809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/transformers/modeling_utils.py:1141: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17207074165344238,\n",
       " 'eval_precision': 0.5220125786163522,\n",
       " 'eval_recall': 0.1456140350877193,\n",
       " 'eval_f1': 0.22770919067215364,\n",
       " 'eval_accuracy': 0.9840231760514135,\n",
       " 'eval_runtime': 12.9829,\n",
       " 'eval_samples_per_second': 50.066,\n",
       " 'eval_steps_per_second': 6.316,\n",
       " 'epoch': 333.3333333333333}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34432fc7-b6bf-4526-9348-b49535e14c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayoutLMv3ForTokenClassification(\n",
       "  (layoutlmv3): LayoutLMv3Model(\n",
       "    (embeddings): LayoutLMv3TextEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (x_position_embeddings): Embedding(1024, 128)\n",
       "      (y_position_embeddings): Embedding(1024, 128)\n",
       "      (h_position_embeddings): Embedding(1024, 128)\n",
       "      (w_position_embeddings): Embedding(1024, 128)\n",
       "    )\n",
       "    (patch_embed): LayoutLMv3PatchEmbeddings(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (encoder): LayoutLMv3Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LayoutLMv3Layer(\n",
       "          (attention): LayoutLMv3Attention(\n",
       "            (self): LayoutLMv3SelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LayoutLMv3SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LayoutLMv3Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LayoutLMv3Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
       "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
       "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): LayoutLMv3ClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(fr\"{path_extraction_folder}/test/checkpoint-1000\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92d266-ab88-4770-9ff9-528d4e7ea849",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Examine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36c43abf-ded9-4c7c-bf67-995b74f9cc3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column image_path not in the dataset. Current columns in the dataset: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_dataset_unmapped\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vt2/lib/python3.11/site-packages/datasets/arrow_dataset.py:2742\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vt2/lib/python3.11/site-packages/datasets/arrow_dataset.py:2726\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2724\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2725\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2726\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2728\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2729\u001b[0m )\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/miniconda3/envs/vt2/lib/python3.11/site-packages/datasets/formatting/formatting.py:590\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    588\u001b[0m         _raise_bad_key_type(key)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 590\u001b[0m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[0;32m~/miniconda3/envs/vt2/lib/python3.11/site-packages/datasets/formatting/formatting.py:527\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column image_path not in the dataset. Current columns in the dataset: ['file_identifier', 'bboxes', 'tokens', 'ner_tags', 'images']\""
     ]
    }
   ],
   "source": [
    "test_dataset_unmapped['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46f26f-4839-46c1-9748-dca51cd8055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_dataset_unmapped[1]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6515d-fbef-40b7-956c-b69bbcc9cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(example['ner_tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9dc24-cf5e-48a3-b25d-b8568a7ab9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset_unmapped[1]['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9be123-6632-43b3-b3d8-9593037c9e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "image = test_dataset_unmapped[1]['image']\n",
    "image = image.convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70dfe28f-4037-45c6-a395-108d3bc52f66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m words \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m boxes \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "images = example[\"image\"]\n",
    "words = example[\"tokens\"]\n",
    "boxes = example[\"bboxes\"]\n",
    "word_labels = example[\"ner_tags\"]\n",
    "\n",
    "encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True, stride =128, \n",
    "         padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True)\n",
    "\n",
    "offset_mapping = encoding.pop('offset_mapping')\n",
    "overflow_to_sample_mapping = encoding.pop('overflow_to_sample_mapping')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7000e8df-70ff-4353-8e27-b9358725bd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'bbox', 'labels', 'pixel_values'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ce49dcc-6a70-4add-ab40-e6a729df32c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(encoding['bbox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "103b976b-1729-4681-b8d2-a5d336772d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the shape of pixel values\n",
    "x = []\n",
    "for i in range(0, len(encoding['pixel_values'])):\n",
    "     x.append(torch.tensor(encoding['pixel_values'][i]))\n",
    "\n",
    "x = torch.stack(x)\n",
    "encoding['pixel_values'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f6486d4-26fd-44f9-9bb8-091f926f001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in encoding.items():\n",
    "#     if isinstance(v, list):\n",
    "#         encoding[k] = torch.tensor(v)\n",
    "#     if k == \"pixel_values\":\n",
    "#         encoding[k] = torch.stack([torch.tensor(pv) for pv in v])\n",
    "#     if k == \"bbox\":\n",
    "#         encoding[k] = encoding[k].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c671a11-4708-4127-b1da-edee39274045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([1, 512])\n",
      "attention_mask torch.Size([1, 512])\n",
      "bbox torch.Size([1, 512, 4])\n",
      "labels torch.Size([1, 512])\n",
      "pixel_values torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for k, v in encoding.items():\n",
    "    if isinstance(v, list):\n",
    "        encoding[k] = torch.tensor(v)\n",
    "    # Ensure 'bbox' is in the correct data type (LongTensor)\n",
    "    if k == 'bbox':\n",
    "        encoding[k] = encoding[k].long()\n",
    "\n",
    "# After conversion, print the shapes again to verify\n",
    "for k, v in encoding.items():\n",
    "    if isinstance(v, (torch.Tensor, np.ndarray)):\n",
    "        print(k, v.shape)\n",
    "    else:\n",
    "        print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b73e18c9-8db0-4e3c-a49d-521a397f8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/transformers/modeling_utils.py:1141: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "predictions = logits.argmax(-1).squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "583d3010-7022-48c7-a0df-d8ef6cc5cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_boxes = encoding.bbox.squeeze().tolist()\n",
    "labels = encoding[\"labels\"].squeeze().tolist()\n",
    "input_ids = encoding[\"input_ids\"].squeeze().tolist()\n",
    "input_words = [processor.tokenizer.decode(id) for id in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fde36db-e3d7-4ca1-9ebf-86a0d461f0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (len(token_boxes) == 512):\n",
    "    predictions = [predictions]\n",
    "    token_boxes = [token_boxes]\n",
    "    labels = [labels]\n",
    "    input_ids = [input_ids]\n",
    "    input_words = [input_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "356e2edc-be7d-4d19-ae51-72d02193f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_box(bbox, width, height):\n",
    "    if isinstance(bbox, (list, tuple)) and len(bbox) == 4:\n",
    "        return [\n",
    "            int(width * (bbox[0] / 1000)),\n",
    "            int(height * (bbox[1] / 1000)),\n",
    "            int(width * (bbox[2] / 1000)),\n",
    "            int(height * (bbox[3] / 1000)),\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Unexpected bbox format: {bbox}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7e7692a-4ca4-48c0-b3b6-fbe8d21cae0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len page_boxes:  182\n",
      "len page_predictions:  182\n",
      "len page_labels:  182\n"
     ]
    }
   ],
   "source": [
    "STRIDE_SIZE=128\n",
    "width = example['image_size']['width']\n",
    "height = example['image_size']['height']\n",
    "true_predictions = []\n",
    "true_labels = []\n",
    "true_boxes = []\n",
    "true_words = []\n",
    "\n",
    "# Process each page of predictions\n",
    "for page_idx in range(len(predictions)):\n",
    "    # Unnormalize bounding boxes for the current page\n",
    "    page_boxes = []\n",
    "    for box, label in zip(token_boxes[page_idx], labels[page_idx]):\n",
    "        if label != -100 and unnormalize_box(box, width, height) is not None:\n",
    "            page_boxes.append(unnormalize_box(box, width, height))\n",
    "\n",
    "    # Extract predictions and labels for the page\n",
    "    page_predictions = []\n",
    "    page_labels = []\n",
    "    for pred, label in zip(predictions[page_idx], labels[page_idx]):\n",
    "        if label != -100:\n",
    "            page_predictions.append(model.config.id2label[int(label)])\n",
    "            page_labels.append(model.config.id2label[label])\n",
    "\n",
    "    print(\"len page_boxes: \", len(page_boxes))\n",
    "    print(\"len page_predictions: \", len(page_predictions))\n",
    "    print(\"len page_labels: \", len(page_labels))\n",
    "\n",
    "    true_boxes.append(page_boxes)\n",
    "    true_predictions.append(page_predictions)\n",
    "    true_labels.append(page_labels)\n",
    "\n",
    "    \n",
    "    page_is_subword = np.array(offset_mapping[page_idx])[:, 0] != 0  # Determine subwords based on offset_mapping\n",
    "\n",
    "    # Extract words, handling subwords and stride adjustments\n",
    "    page_true_words = []\n",
    "    for idx, (i_ids_, is_sub) in enumerate(zip(input_ids[page_idx], page_is_subword)):\n",
    "        # Combine subwords into full words\n",
    "        if not is_sub:\n",
    "            page_true_words.append(processor.tokenizer.decode(i_ids_))  # New word\n",
    "        else:\n",
    "            page_true_words[-1] += processor.tokenizer.decode(i_ids_)  # Add subword to the last word\n",
    "\n",
    "    # Apply stride adjustments for subsequent pages\n",
    "    if page_idx > 0:\n",
    "        # Handling stride offsets for subsequent pages\n",
    "        stride_offset = 1 + STRIDE_SIZE - sum(page_is_subword[:1 + STRIDE_SIZE])\n",
    "        page_true_words = page_true_words[stride_offset:]\n",
    "\n",
    "    true_words.append(page_true_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "016e1686-9d90-4df6-8a46-08e6ce74ff6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iob_to_label(tag):\n",
    "    \"\"\"\n",
    "    Converts an IOB tag to its identifier and label.\n",
    "    Args:\n",
    "        tag (str): IOB tag in the format B-<label>, I-<label>, or O.\n",
    "    Returns:\n",
    "        tuple: (identifier, label) where identifier is 'B', 'I', or 'O' and label is the entity type.\n",
    "    \"\"\"\n",
    "    if tag == \"O\":\n",
    "        return \"O\", \"\"\n",
    "    identifier, label = tag.split(\"-\", 1)\n",
    "    return identifier, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbb7ca6d-aa98-419a-91be-f7cb543c1f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "preds, l_words, bboxes = [], [], []\n",
    "\n",
    "# Iterate through true predictions to filter out non-entity labels (e.g., 'O')\n",
    "for page_idx in range(len(true_predictions)):\n",
    "    for idx, _pred in enumerate(true_predictions[page_idx]):\n",
    "        if _pred != 'O':  # Filter out non-entities\n",
    "            preds.append(true_predictions[page_idx][idx])\n",
    "            l_words.append(true_words[page_idx][idx])\n",
    "            bboxes.append(true_boxes[page_idx][idx])\n",
    "\n",
    "# Extract entities using IOB formatting\n",
    "extractions: dict[str, list[str]] = {}\n",
    "\n",
    "# Iterate through the predictions to extract entities\n",
    "for idx, _preds in enumerate(preds):\n",
    "    identifier, label = iob_to_label(_preds)  # Convert IOB to label\n",
    "    label = label.lower()\n",
    "\n",
    "    # Handle entity extraction\n",
    "    if label not in extractions:\n",
    "        extractions[label] = [l_words[idx]]  # Start a new entity\n",
    "    else:\n",
    "        if identifier == 'B':  # Beginning of a new entity\n",
    "            extractions[label].append(l_words[idx])\n",
    "        else:  # Continuation of the current entity\n",
    "            extractions[label][-1] += l_words[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7af16465-4f7a-4a1a-b27c-d7e007bd7cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1a4c6-00fb-47e0-a4ee-2c12de13a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817ec177-23ba-46a6-b582-223e8be8125d",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdb16625-6d52-48e3-99be-fe1d659e77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def process_single_example(example, processor, model, stride_size=128, max_length=512):\n",
    "    \"\"\"\n",
    "    Processes a single example from the dataset for inference.\n",
    "    \"\"\"\n",
    "    images = example[\"images\"]\n",
    "    words = example[\"tokens\"]\n",
    "    boxes = example[\"bboxes\"]\n",
    "    word_labels = example[\"ner_tags\"]\n",
    "\n",
    "    # Ensure input lengths match\n",
    "    assert len(words) == len(boxes) == len(word_labels), \\\n",
    "        f\"Mismatch in input lengths: tokens={len(words)}, bboxes={len(boxes)}, ner_tags={len(word_labels)}\"\n",
    "\n",
    "    encoding = processor(\n",
    "        images, words, boxes=boxes, word_labels=word_labels, truncation=True, stride=stride_size,\n",
    "        padding=\"max_length\", max_length=max_length, return_overflowing_tokens=True, return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "    overflow_to_sample_mapping = encoding.pop('overflow_to_sample_mapping')\n",
    "\n",
    "    # Convert pixel values to tensor\n",
    "    encoding['pixel_values'] = torch.stack([torch.tensor(pv) for pv in encoding['pixel_values']])\n",
    "\n",
    "    # Convert other items to tensors\n",
    "    for k, v in encoding.items():\n",
    "        if isinstance(v, list):\n",
    "            encoding[k] = torch.tensor(v)\n",
    "        if k == 'bbox':  # Ensure 'bbox' is LongTensor\n",
    "            encoding[k] = encoding[k].long()\n",
    "\n",
    "    return encoding, offset_mapping\n",
    "\n",
    "def process_predictions(encoding, model, offset_mapping, stride_size=128, width=None, height=None):\n",
    "    \"\"\"\n",
    "    Process predictions from the model output, accounting for stride overlaps \n",
    "    and filtering invalid tokens (e.g., labels with -100).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Convert logits to predictions\n",
    "    predictions = logits.argmax(-1).tolist()  # Shape: [num_chunks, sequence_length]\n",
    "    labels = encoding[\"labels\"].tolist()\n",
    "    token_boxes = encoding[\"bbox\"].tolist()\n",
    "\n",
    "    true_predictions, true_labels = [], []\n",
    "\n",
    "    for i, (preds, lbls, offsets) in enumerate(zip(predictions, labels, offset_mapping)):\n",
    "\n",
    "        # Filter out tokens in the stride overlap\n",
    "        non_overlap_indices = [idx for idx, offset in enumerate(offsets) if offset[0] == 0]\n",
    "\n",
    "        if not non_overlap_indices:\n",
    "            print(f\"No valid indices found for chunk {i}, skipping...\")\n",
    "            continue  # Skip if no valid tokens remain\n",
    "\n",
    "        filtered_preds = [preds[idx] for idx in non_overlap_indices]\n",
    "        filtered_lbls = [lbls[idx] for idx in non_overlap_indices]\n",
    "\n",
    "        # Map to label names, excluding ignored labels (-100)\n",
    "        chunk_predictions = [\n",
    "            label_list[p] for (p, l) in zip(filtered_preds, filtered_lbls) if l != -100\n",
    "        ]\n",
    "        chunk_labels = [\n",
    "            label_list[l] for (p, l) in zip(filtered_preds, filtered_lbls) if l != -100\n",
    "        ]\n",
    "\n",
    "        # Append non-empty predictions and labels\n",
    "        if chunk_predictions and chunk_labels:\n",
    "            true_predictions.append(chunk_predictions)\n",
    "            true_labels.append(chunk_labels)\n",
    "\n",
    "    # Safeguard: Handle case with no valid predictions\n",
    "    if not true_predictions or not true_labels:\n",
    "        print(\"Warning: No valid predictions or labels found!\")\n",
    "        true_predictions = [[]]\n",
    "        true_labels = [[]]\n",
    "\n",
    "    return true_predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ed4b58-afa1-4d2f-89cb-839edddb61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def process_and_evaluate(true_predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Processes a single example, performs predictions, and computes evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "        example (dict): A dictionary containing the example data.\n",
    "        processor: The processor to prepare inputs for the model.\n",
    "        model: The trained model for inference.\n",
    "        stride_size (int): The stride size for tokenization.\n",
    "        max_length (int): The maximum sequence length.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing predictions, ground truths, and evaluation metrics.\n",
    "    \"\"\"\n",
    "    metric = evaluate.load(\"seqeval\")\n",
    "    return_entity_level_metrics = False\n",
    "    \n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8758e865-8578-4771-86ea-a6dd41f51e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(dataset, processor, model, stride_size=128, max_length=512):\n",
    "    \"\"\"\n",
    "    Processes the entire dataset by running inference for each example.\n",
    "    \"\"\"\n",
    "    all_extractions = []\n",
    "    results = []\n",
    "\n",
    "    for example in dataset:\n",
    "        image = example['images']\n",
    "        width, height = image.size\n",
    "\n",
    "        # Process the example\n",
    "        encoding, offset_mapping = process_single_example(example, processor, model, stride_size, max_length)\n",
    "\n",
    "        # Get model predictions\n",
    "        true_predictions, true_labels = process_predictions(\n",
    "            encoding, model, offset_mapping, stride_size, width, height\n",
    "        )\n",
    "\n",
    "        # Compute and collect metrics\n",
    "        result = process_and_evaluate(true_predictions, true_labels)\n",
    "        results.append(result)\n",
    "\n",
    "        # Aggregate metrics\n",
    "        all_metrics = {\n",
    "            \"precision\": np.mean([r[\"precision\"] for r in results]),\n",
    "            \"recall\": np.mean([r[\"recall\"] for r in results]),\n",
    "            \"f1\": np.mean([r[\"f1\"] for r in results]),\n",
    "            \"accuracy\": np.mean([r[\"accuracy\"] for r in results]),\n",
    "        }\n",
    "\n",
    "       \n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "241ddc00-238d-4d8a-9d5f-42091cd172aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/gaye/miniconda3/envs/vt2/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "all_metrics = run_inference(test_dataset_unmapped, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96b11c73-10b8-4886-b63c-6941a1bee482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.41568627450980394,\n",
       " 'recall': 0.18568627450980393,\n",
       " 'f1': 0.23635854341736692,\n",
       " 'accuracy': 0.9872562564616157}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb4abdf0-b384-4242-89a4-fe1909c80495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics, file info, and predictions saved to layoutlmv3_outputs/FARA-lv3-unk_Short-Form-train_10-test_300-valid_100-SD_0/model_metrics_with_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample metrics dictionary after calculating with compute_metrics function\n",
    "all_metrics = {\n",
    "    \"precision\": all_metrics[\"precision\"],\n",
    "    \"recall\": all_metrics[\"recall\"],\n",
    "    \"f1\": all_metrics[\"f1\"],\n",
    "    \"accuracy\": all_metrics[\"accuracy\"]\n",
    "}\n",
    "\n",
    "# File information and dataset counts\n",
    "file_info = {\n",
    "    \"num_train_samples\": len(dataset_splits['train_split']),\n",
    "    \"num_valid_samples\": 100,\n",
    "    \"num_test_samples\": len(dataset_splits['test_split']),\n",
    "}\n",
    "\n",
    "# Combine metrics, metadata, and predictions/ground truths into a single dictionary\n",
    "output_data = {\n",
    "    split_file_name: {\n",
    "    \"metrics\": all_metrics,\n",
    "    \"file_info\": file_info\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# Save the combined data to a JSON file\n",
    "output_file_path = (fr\"{path_extraction_folder}/model_metrics_with_predictions.json\")\n",
    "with open(output_file_path, \"w\") as json_file:\n",
    "    json.dump(output_data, json_file, indent=4, ensure_ascii=False)  # ensure_ascii=False for non-ASCII characters\n",
    "\n",
    "print(f\"Metrics, file info, and predictions saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4659288-0ff4-49d3-a25c-ce22acff18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
